{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "Load \"izquierda diario\" dataset from csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/izq_econ_news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>flyer</th>\n",
       "      <th>lead</th>\n",
       "      <th>headline</th>\n",
       "      <th>body</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\\nLunes 30 de noviembre</td>\n",
       "      <td>SENADO</td>\n",
       "      <td>El objetivo sería “proteger a la Argentina de ...</td>\n",
       "      <td>¿Qué dice la ley de “sostenibilidad de la deud...</td>\n",
       "      <td>Este lunes los senadores dieron media sanción ...</td>\n",
       "      <td>https://www.laizquierdadiario.com/Economia/Que...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\\nLunes 30 de noviembre</td>\n",
       "      <td>ECONOMÍA</td>\n",
       "      <td>El ministro de Trabajo, Claudio Moroni, confir...</td>\n",
       "      <td>Doble indemnización: pese a no frenar los desp...</td>\n",
       "      <td>El Gobierno nacional prorrogó hasta el próximo...</td>\n",
       "      <td>https://www.laizquierdadiario.com/Economia/Dob...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>\\nDomingo 29 de noviembre</td>\n",
       "      <td>AJUSTAN AL SALARIO</td>\n",
       "      <td>El último tramo del aumento se pagaría con el ...</td>\n",
       "      <td>Paritarias estatales de Jujuy: ¿qué cambia con...</td>\n",
       "      <td>El viernes 27/11 por la tarde el Gobierno lueg...</td>\n",
       "      <td>https://www.laizquierdadiario.com/Economia/Par...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\\nSábado 28 de noviembre</td>\n",
       "      <td>JUBILACIONES</td>\n",
       "      <td>El proyecto del Ejecutivo para una nueva ley d...</td>\n",
       "      <td>Escándalo: el Gobierno quiere descontar a los ...</td>\n",
       "      <td>En un nuevo intento de robo a los jubilados, e...</td>\n",
       "      <td>https://www.laizquierdadiario.com/Economia/Esc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>\\nSábado 28 de noviembre</td>\n",
       "      <td>A PEDIDO DEL FMI</td>\n",
       "      <td>Se oficializa el ataque a las jubilaciones y p...</td>\n",
       "      <td>Ajuste a jubilados: el Gobierno envió al Congr...</td>\n",
       "      <td>El Ejecutivo giró este sábado al Congreso su p...</td>\n",
       "      <td>https://www.laizquierdadiario.com/Economia/Aju...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                       date                flyer  \\\n",
       "0           0    \\nLunes 30 de noviembre               SENADO   \n",
       "1           1    \\nLunes 30 de noviembre             ECONOMÍA   \n",
       "2           2  \\nDomingo 29 de noviembre  AJUSTAN AL SALARIO    \n",
       "3           3   \\nSábado 28 de noviembre         JUBILACIONES   \n",
       "4           4   \\nSábado 28 de noviembre     A PEDIDO DEL FMI   \n",
       "\n",
       "                                                lead  \\\n",
       "0  El objetivo sería “proteger a la Argentina de ...   \n",
       "1  El ministro de Trabajo, Claudio Moroni, confir...   \n",
       "2  El último tramo del aumento se pagaría con el ...   \n",
       "3  El proyecto del Ejecutivo para una nueva ley d...   \n",
       "4  Se oficializa el ataque a las jubilaciones y p...   \n",
       "\n",
       "                                            headline  \\\n",
       "0  ¿Qué dice la ley de “sostenibilidad de la deud...   \n",
       "1  Doble indemnización: pese a no frenar los desp...   \n",
       "2  Paritarias estatales de Jujuy: ¿qué cambia con...   \n",
       "3  Escándalo: el Gobierno quiere descontar a los ...   \n",
       "4  Ajuste a jubilados: el Gobierno envió al Congr...   \n",
       "\n",
       "                                                body  \\\n",
       "0  Este lunes los senadores dieron media sanción ...   \n",
       "1  El Gobierno nacional prorrogó hasta el próximo...   \n",
       "2  El viernes 27/11 por la tarde el Gobierno lueg...   \n",
       "3  En un nuevo intento de robo a los jubilados, e...   \n",
       "4  El Ejecutivo giró este sábado al Congreso su p...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.laizquierdadiario.com/Economia/Que...  \n",
       "1  https://www.laizquierdadiario.com/Economia/Dob...  \n",
       "2  https://www.laizquierdadiario.com/Economia/Par...  \n",
       "3  https://www.laizquierdadiario.com/Economia/Esc...  \n",
       "4  https://www.laizquierdadiario.com/Economia/Aju...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['SENADO', 'ECONOMÍA', 'AJUSTAN AL SALARIO ', 'JUBILACIONES',\n",
       "       'A PEDIDO DEL FMI', 'CONSUMO', 'CIERRE DE MINA AGUILAR S.A.',\n",
       "       'BRECHA CAMBIARIA', 'INFORME INDEC', 'OPTIMISMO EN LOS “MERCADOS”',\n",
       "       'INFORME INDEC', 'LEVANTARLA EN PALA',\n",
       "       'SEMANA ECONÓMICA EN CLAVES', 'INFLACIÓN', 'ESTADOS UNIDOS',\n",
       "       'INFLACION', 'SOCIEDAD', 'AJUSTE A PEDIDO DEL FMI ',\n",
       "       'TARIFAS E INFLACIÓN', 'CHANTAJE EMPRESARIAL ', 'TRIBUNA ABIERTA',\n",
       "       'TUCUMÁN', 'CUMBRE DEL G20', 'PRECIOS', 'COMUNICADO DE PRENSA',\n",
       "       'DOBLE DISCURSO', 'LICITACIÓN', 'AJUSTE',\n",
       "       'ESTIMACIÓN JUNTA INTERNA ATE INDEC', 'INFORME INDEC', 'AJUSTE',\n",
       "       'ANUNCIO OFICIAL', 'EXPORTACIONES', 'DÓLAR Y BRECHA',\n",
       "       'CELEBRAN LAS PATRONALES AGRARIAS', 'INFORME INDEC', 'AJUSTE',\n",
       "       'PRESUPUESTO 2021', 'MULTINACIONALES MINERAS',\n",
       "       'GANANCIA EMPRESARIA', 'NO AL AJUSTE A PEDIDO DEL FMI',\n",
       "       'COMERCIO INTERNACIONAL', 'MULTINACIONALES MINERAS', 'ACTUALIDAD',\n",
       "       'ENTREVISTA', 'CONSUMO MASIVO', 'PATEANDO EL TABLERO ',\n",
       "       'Decile Como Quieras Ep 29', 'SAQUEO A LA CLASE TRABAJADORA',\n",
       "       'ANUNCIÓ OBRAS', 'CONGRESO NACIONAL', 'TIPO DE CAMBIO',\n",
       "       'BENEFICIOS PARA EMPRESAS',\n",
       "       'En Economía, DECÍMELA FÁCIL - CAPÍTULO 4', 'SUBA DE PRECIOS',\n",
       "       'BCRA', 'GOLPE AL BOLSILLO', 'INFORME INDEC', 'NUEVA MEDIDA',\n",
       "       'TIPO DE CAMBIO', 'EN EL FONDO', 'FESTEJA EL CAMPO',\n",
       "       'TENSION CAMBIARIA', 'JUBILACIONES', 'Deuda municipal',\n",
       "       'ALERTA SPOILER', 'ENDEUDAMIENTO', 'MISIÓN DEL FONDO EN ARGENTINA',\n",
       "       'ROBO A LOS JUBILADOS ', 'BUEN FIN CDMX', 'DÉFICIT HABITACIONAL',\n",
       "       'TIPO DE CAMBIO', 'CRISIS', 'CRISIS Y AJUSTE', 'ALERTA SPOILER',\n",
       "       'DEUDA EXTERNA', 'PANDEMIA, CRISIS Y AJUSTE', 'JUBILACIONES',\n",
       "       'DEUDA EXTERNA', 'DEUDA IMPAGABLE', 'DEUDA EXTERNA',\n",
       "       'DEFENSA DEL SALARIO ', 'ACTUALIDAD', 'ENDEUDAMIENTO',\n",
       "       'NEGOCIOS MILLONARIOS ', 'PÉRDIDA DE RESERVAS DEL BANCO CENTRAL',\n",
       "       'ECONOMÍA', 'ECONOMÍA INTERNACIONAL', 'INFORME INDEC',\n",
       "       'REUNIÓN CON LOS DUEÑOS DEL PAÍS', 'CRISIS ECONOMICA',\n",
       "       'CONGRESO NACIONAL', 'ENDEUDAMIENTO',\n",
       "       'ELECCIONES EN ESTADOS UNIDOS', 'CRISIS CAMBIARIA',\n",
       "       'CRISIS ECONOMICA', 'ACTUALIDAD', 'COMUNICADO DE PRENSA',\n",
       "       'SEMANARIO IDEAS DE IZQUIERDA', 'DÓLAR',\n",
       "       'HAY PRIORIDADES Y PRIORIDADES', 'ECONOMIA',\n",
       "       'LO MISMO DE SIEMPRE ', 'RECLAMOS', 'BCRA', 'INFORME ESPECIAL',\n",
       "       'ANUNCIO OFICIAL', 'Deuda Pública ', 'INFORME INDEC', nan,\n",
       "       'TIPO DE CAMBIO', 'ENDEUDAMIENTO', 'PRIORIDADES',\n",
       "       'CRISIS INTERNACIONAL', 'CHARLAS ENTRE AMIGOS', 'CRISIS',\n",
       "       'DECLARACIONES', 'BONO ATADO AL DÓLAR', 'Panorama Provincial',\n",
       "       'ACTUALIDAD', 'ALERTA SPOILER', 'TENSION CAMBIARIA',\n",
       "       'ECONOMÍA INTERNACIONAL', 'CRISIS DEL DÓLAR ', 'CRISIS ECONOMICA',\n",
       "       'TENSION CAMBIARIA', 'ACTUALIDAD', nan, 'A 91 AÑOS',\n",
       "       'ESTIMACIÓN JUNTA INTERNA ATE INDEC', 'CONGRESO NACIONAL',\n",
       "       'ECONOMIA', 'TENSIÓN CAMBIARIA ', 'CRÍTICAS AL GOBIERNO',\n",
       "       'ACTUALIDAD', 'NEGOCIAN NUEVO ACUERDO', 'PRESUPUESTO 2021',\n",
       "       'INFORME INDEC ', 'MERCADO DE DIVISAS',\n",
       "       'ENCUENTRO IBEROAMERICANO CON EMPRESARIOS', 'MEDIDAS OFICIALES',\n",
       "       'INDEC', 'TENSIÓN CAMBIARIA', 'NUEVAS MEDIDAS OFICIALES '],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.flyer.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics\n",
    "Find from flyers the different topics inside the section about economy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.flyer.str.contains('DEUDA|Deuda|BONO', na=False)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.flyer.str.contains('BRECHA|CAMBI|RESERV', na=False)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.flyer.str.contains('INFLA|INDEC|SUBA|PRECIO', na=False)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.flyer.str.contains('FMI|FONDO', na=False)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.flyer.str.contains('SALARIO|OBRER|TRABAJA', na=False)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus (Body)\n",
    "Get the body of those news which cover topics about inflation and the rate of exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inflation = df.loc[df.flyer.str.contains('INFLA|INDEC|SUBA|PRECIO', na=False),'body'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exchange = df.loc[df.flyer.str.contains('BRECHA|CAMBI|RESERV', na=False), 'body'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = list(df_inflation) + list(df_exchange)\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "#### Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unidecode\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Stop words\", special characters, accents and numbers are removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_sp = stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(texto):\n",
    "\n",
    "    alphanumeric = re.sub(r'([^\\s\\w]|_)+', '', texto).lower()\n",
    "    no_accents = unidecode.unidecode(alphanumeric)\n",
    "    \n",
    "    tockens = word_tokenize(no_accents)\n",
    "    \n",
    "    tockens_clean = [tocken for tocken in tockens if tocken not in stopwords_sp and tocken.isalpha()]\n",
    "    \n",
    "    terminos = tockens_clean\n",
    "\n",
    "    return terminos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = [tokenizer(documento) for documento in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulario = sorted(list(set([word for group in tokenized for word in group])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2034"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words = stopwords_sp, lowercase = True, strip_accents='unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning = [re.sub(r'(\\d|\\$|\\%|\\+)', '', doc) for doc in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guido/anaconda3/envs/dh/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CountVectorizer(stop_words=['de', 'la', 'que', 'el', 'en', 'y', 'a', 'los',\n",
       "                            'del', 'se', 'las', 'por', 'un', 'para', 'con',\n",
       "                            'no', 'una', 'su', 'al', 'lo', 'como', 'más',\n",
       "                            'pero', 'sus', 'le', 'ya', 'o', 'este', 'sí',\n",
       "                            'porque', ...],\n",
       "                strip_accents='unicode')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1936, 1936)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.vocabulary_), len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I prefare the manual tokenization results since more terms could be saved."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare tokens and pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_matrix_maker(data, vocabulario):\n",
    "    matriz = np.zeros(shape = (len(data), len(vocabulario)), dtype='int')\n",
    "    for i, documento in enumerate(data):\n",
    "        for termino in documento:\n",
    "            matriz[i, vocabulario.index(termino)] += 1\n",
    "    return matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = token_matrix_maker(tokenized, vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_inflation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataframe\n",
    "token_df = pd.DataFrame(matrix, columns=vocabulario, index = ['doc' + str(i + 1) for i in range(len(tokenized))] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add classification column\n",
    "topics = ['inflation' for i in range(len(df_inflation))] + ['exchange' for i in range(len(df_exchange))]\n",
    "token_df.insert(loc=0, column='topics', value=topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_df.to_pickle('tokens/topic_tokens_izq.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
