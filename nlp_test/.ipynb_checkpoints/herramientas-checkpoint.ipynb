{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Herramientas de Análisis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Desafío\n",
    "\n",
    "¿Cuáles son las condiciones fundamentales para implementar modelos de ML capaces de clasificar/catalogar textos?\n",
    "\n",
    "El primer objetivo consiste en representar los datos brindados por el texto como una matriz de features. Para los modelos de aprendizaje supervisado, es indispensable contar con una etiqueta de clasificación (spam vs ham, bueno vs malo)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los textos son secuencias de palabras y signos de puntuación cuyo sentido está contenido en las estructuras semánticas que combinan o articulan u ordenan de una cierta manera los elementos que los componen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En definitiva, ¿cómo ordernar una biblioteca o **corpus** de textos o **documentos** con herramientas de machine learning? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dimensionalidad\n",
    "\n",
    "La tarea de organizar la biblioteca implica comparar textos, comparándolos y buscando parecidos entre sí. En definitiva, hallar una estructura subyacente entre los textos, presentes y posibles. ¿Cómo acotar la dimensionalidad del horizonte de textos posibles?\n",
    "\n",
    "El entrenamiento de los algoritmos de ML que nos permita encontrar patrones entre los datos y el posterior análisis de las métricas de distancia entre los textos requiere definir **representaciones reducidas de los textos**.\n",
    "\n",
    "De antemano, es necesario excluir cualquier combinación de caracteres que no formen palabras de un vocabulario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Representaciones de los Textos\n",
    "\n",
    "La \"tockenización\" o representación reducida de los textos consiste en conservar únicamente el conjunto de palabras y el número de veces que aparecen en un documento, descartando el orden y estructura gramatical (las reglas semánticas que le dan sentido). \n",
    "\n",
    "Problema: cualquier sea el orden y la articulación de la palabras, textos con diferentes sentidos serían representados de la misma manera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unidades de análisis:\n",
    "\n",
    "- **Corpus**  = conjunto de textos/documentos. \n",
    "- **Documento** = cada texto que compone el corpus y que se puede reducir a la unidad de un dato."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pasos para computar la representación de un corpus de documentos:\n",
    "\n",
    "1. Tokenización: convertir cada documento a una lista de palabras (y signos de puntuación).\n",
    "2. Construcción de un vocabulario: colectar todas las palabras que se registraron en el **corpus** y ordenarlas (típicamente por orden alfabético).\n",
    "3. Encoding: representar los documentos como vectores en el espacio de las palabras del vocabulario."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tockenización\n",
    "(reducción de la dimensionalidad)\n",
    "\n",
    "Transformación de un texto a unidades constitutivas llamadas tokens, palabras y signos de puntuación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/izq_econ_news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = str(df.loc[11,'headline'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Las petroleras saludan el Plan Gas del Gobierno: “Una señal positiva para los privados”'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Las',\n",
       " 'petroleras',\n",
       " 'saludan',\n",
       " 'el',\n",
       " 'Plan',\n",
       " 'Gas',\n",
       " 'del',\n",
       " 'Gobierno:',\n",
       " '“Una',\n",
       " 'señal',\n",
       " 'positiva',\n",
       " 'para',\n",
       " 'los',\n",
       " 'privados”']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence.split(' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Las',\n",
       " 'petroleras',\n",
       " 'saludan',\n",
       " 'el',\n",
       " 'Plan',\n",
       " 'Gas',\n",
       " 'del',\n",
       " 'Gobierno',\n",
       " ':',\n",
       " '“',\n",
       " 'Una',\n",
       " 'señal',\n",
       " 'positiva',\n",
       " 'para',\n",
       " 'los',\n",
       " 'privados',\n",
       " '”']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "nltk identifica casi siempre las funciones que cumplen los signos de puntuación (desde separar oraciones a formar abreviaturas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_2 = pd.read_csv('../data/derecha_econ_news.csv')\n",
    "paragraph = df_2.title[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Socialismo y miseria: la economía venezolana cayó un 50,44% en el tercer trimestre de este año y la inflación supera el 3.000%'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizamos usando split:\n",
      "['Socialismo y miseria: la economía venezolana cayó un 50,44% en el tercer trimestre de este año y la inflación supera el 3', '000%']\n",
      "\n",
      "Tokenizamos usando sent_tokenize:\n",
      "['Socialismo y miseria: la economía venezolana cayó un 50,44% en el tercer trimestre de este año y la inflación supera el 3.000%']\n"
     ]
    }
   ],
   "source": [
    "print('Tokenizamos usando split:')\n",
    "print(paragraph.split('.'))\n",
    "print()\n",
    "print('Tokenizamos usando sent_tokenize:')\n",
    "print(sent_tokenize(paragraph))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El tokenizador es configurable y se pueden incluir abreviaturas. En lugar de importar *sent_tokenize* se instancia los objetos *PunkTrainer* y *PunktSentenceTokenizer*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<nltk.tokenize.punkt.PunktParameters object at 0x7f7a314a7790>\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize.punkt import PunktSentenceTokenizer, PunktTrainer\n",
    "\n",
    "# se entrena el PunktTrainer\n",
    "trainer = PunktTrainer()\n",
    "trainer.INCLUDE_ALL_COLLOCS = True\n",
    "print(trainer.get_params())\n",
    "\n",
    "# se usa el PunktSentenceTokenizer con el PunktTrainer como parametro\n",
    "tokenizer = PunktSentenceTokenizer(trainer.get_params())\n",
    "tokenizer._params.abbrev_types.add('al')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "According to Hotho et al. (2005) we can differ three different perspectives of text mining, namely text mining as information extraction, text mining as text data mining, and text mining as KDD (Knowledge Discovery in Databases) process. Text mining is 'the discovery by computer of new, previously unknown information, by automatically extracting information from different written resources.\n",
      "\n",
      "['According to Hotho et al.', '(2005) we can differ three different perspectives of text mining, namely text mining as information extraction, text mining as text data mining, and text mining as KDD (Knowledge Discovery in Databases) process.', \"Text mining is 'the discovery by computer of new, previously unknown information, by automatically extracting information from different written resources.\"]\n",
      "\n",
      "['According to Hotho et al. (2005) we can differ three different perspectives of text mining, namely text mining as information extraction, text mining as text data mining, and text mining as KDD (Knowledge Discovery in Databases) process.', \"Text mining is 'the discovery by computer of new, previously unknown information, by automatically extracting information from different written resources.\"]\n"
     ]
    }
   ],
   "source": [
    "example = \"According to Hotho et al. (2005) we can differ three different perspectives of text mining, namely text mining as information extraction, text mining as text data mining, and text mining as KDD (Knowledge Discovery in Databases) process. Text mining is 'the discovery by computer of new, previously unknown information, by automatically extracting information from different written resources.\"\n",
    "print(example)\n",
    "print()\n",
    "print(sent_tokenize(example))\n",
    "print()\n",
    "print(tokenizer.tokenize(example))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'al'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view abbrevations\n",
    "tokenizer._params.abbrev_types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generación del vocabulario\n",
    "(reducción de la dimensionalidad)\n",
    "\n",
    "Conjunto de palabras que aparecen al menos una vez en todo el corpus. Para su construcción se requiere reducir la dimensionalidad del texto mediante:\n",
    "\n",
    "1. Al excluir las palabras menos informativas sobre el contenido del texto, como las preposiciones, pronombres, artículos, etc.\n",
    "\n",
    "2. Al agrupar palabras que comparten la misma raíz etimológica como \"correr\", \"corriendo\", \"corredor\". Los objetos de ntlk se alimentan sólo de las palabras y requieren la **eliminación de acentos y signos de puntuación**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.  Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Las primeras 20 en español:\n",
      "['de', 'la', 'que', 'el', 'en', 'y', 'a', 'los', 'del', 'se', 'las', 'por', 'un', 'para', 'con', 'no', 'una', 'su', 'al', 'lo']\n"
     ]
    }
   ],
   "source": [
    "stopwords_sp = stopwords.words('spanish');\n",
    "\n",
    "print('\\nLas primeras 20 en español:')\n",
    "print(stopwords_sp[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.a. Stemming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consiste en la sustracción de sufijos y prefijos de las palabras. La raíz que queda (stem) muchas veces no es una palabra en sí misma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inglés\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "# español\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corriendo\n",
      "corr\n"
     ]
    }
   ],
   "source": [
    "palabra = 'corriendo'\n",
    "\n",
    "spanishStemmer = SnowballStemmer(\"spanish\")\n",
    "stemm = spanishStemmer.stem(palabra)\n",
    "\n",
    "print(f'{palabra}\\n{stemm}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_stemmer(frase):\n",
    "    podador = SnowballStemmer(\"spanish\", ignore_stopwords=True)\n",
    "    frase_podada = str()\n",
    "    for palabra in word_tokenize(frase):\n",
    "        frase_podada += podador.stem(palabra) + ' '\n",
    "    return frase_podada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se oficializa el ataque a las jubilaciones y pensiones con el envió al Congreso del proyecto de ley que modifica la movilidad jubilatoria suspendida\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'se oficializ el ataqu a las jubil y pension con el envi al congres del proyect de ley que modif la movil jubilatori suspend '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frase = df.lead[4].split('.')[0]\n",
    "print(frase)\n",
    "print()\n",
    "sp_stemmer(frase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.b. Lemmatización"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El lematizador devuelve una versión reducida de la palabra (lema), pero que es en sí misma una palabra de la misma familia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sólo en ingles\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'He was running and eating at same time  He has bad habit of swimming after playing long hours in the Sun '"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_raw = \"He was running and eating at same time. He has bad habit of swimming after playing long hours in the Sun.\"\n",
    "sentence = sentence_raw.replace('.',' ')\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_tockens = word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordnet_lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He\n",
      "wa\n",
      "running\n",
      "and\n",
      "eating\n",
      "at\n",
      "same\n",
      "time\n",
      "He\n",
      "ha\n",
      "bad\n",
      "habit\n",
      "of\n",
      "swimming\n",
      "after\n",
      "playing\n",
      "long\n",
      "hour\n",
      "in\n",
      "the\n",
      "Sun\n"
     ]
    }
   ],
   "source": [
    "for word in sentence_tockens:\n",
    "    print(wordnet_lemmatizer.lemmatize(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modelo de Tockenización (en español)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Remover signos de puntución, transformar a minúsculas y eliminar tildes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "oracion_cruda = df_2.lead[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'durante los primeros nueve meses del año las empresas públicas argentinas necesitaron ese importa para sobrevivir un 60% más que el año pasado cuando la cifra se situaba en $334 millones por día'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracion_min_alpha_1 = oracion_cruda.lower().replace('.','').replace(',','')\n",
    "oracion_min_alpha_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Problema: signos de puntuación removidos y todo a minúsculas, pero permanecen otros signos\n",
    "- Solución: usar re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'durante los primeros nueve meses del año las empresas públicas argentinas necesitaron ese importa para sobrevivir un 60 más que el año pasado cuando la cifra se situaba en 334 millones por día'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "oracion_min_alpha_2  = re.sub(r'([^\\s\\w]|_)+','',oracion_cruda).lower()\n",
    "oracion_min_alpha_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unidecode\n",
    "\n",
    "oracion = unidecode.unidecode(oracion_min_alpha_2.lower())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- con unidecode remuevo tildes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'durante los primeros nueve meses del ano las empresas publicas argentinas necesitaron ese importa para sobrevivir un 60 mas que el ano pasado cuando la cifra se situaba en 334 millones por dia'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "oracion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Tockenizar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_sp = stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# me quedo con las palabras\n",
    "tockens = word_tokenize(oracion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# elimino stopwords\n",
    "tockens_clean = [tocken for tocken in tockens if tocken not in stopwords_sp]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['primeros',\n",
       " 'nueve',\n",
       " 'meses',\n",
       " 'ano',\n",
       " 'empresas',\n",
       " 'publicas',\n",
       " 'argentinas',\n",
       " 'necesitaron',\n",
       " 'importa',\n",
       " 'sobrevivir',\n",
       " '60',\n",
       " 'mas',\n",
       " 'ano',\n",
       " 'pasado',\n",
       " 'cifra',\n",
       " 'situaba',\n",
       " '334',\n",
       " 'millones',\n",
       " 'dia']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tockens_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Confeccionar el vocabulario del corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulario = set(tockens_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'334',\n",
       " '60',\n",
       " 'ano',\n",
       " 'argentinas',\n",
       " 'cifra',\n",
       " 'dia',\n",
       " 'empresas',\n",
       " 'importa',\n",
       " 'mas',\n",
       " 'meses',\n",
       " 'millones',\n",
       " 'necesitaron',\n",
       " 'nueve',\n",
       " 'pasado',\n",
       " 'primeros',\n",
       " 'publicas',\n",
       " 'situaba',\n",
       " 'sobrevivir'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tockenización múltiple\n",
    "(manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INFORME INDEC        7\n",
       "ACTUALIDAD           6\n",
       "ENDEUDAMIENTO        4\n",
       "TIPO DE CAMBIO       4\n",
       "AJUSTE               3\n",
       "TENSION CAMBIARIA    3\n",
       "JUBILACIONES         3\n",
       "ALERTA SPOILER       3\n",
       "DEUDA EXTERNA        3\n",
       "CRISIS ECONOMICA     3\n",
       "Name: flyer, dtype: int64"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.flyer.value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'El proyecto del Ejecutivo para una nueva ley de movilidad previsional incluye un artículo que considera el aumento del 5 % otorgado en diciembre como un pago a cuenta del aumento de marzo. Ajuste explícito a la medida del FMI. Mirá el proyecto completo.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc1 = str(list(df[df.flyer == 'JUBILACIONES'].lead)[0])\n",
    "doc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'La suspensión de la movilidad previsional y su reemplazo por aumentos discrecionales por decreto implicaron un robo a los jubilados en estos 12 meses. Ahora el Gobierno buscará cambiar la ley de actualización de haberes de acuerdo a las exigencias del FMI de quitar el componente inflacionario.'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2 = str(list(df[df.flyer == 'JUBILACIONES'].lead)[1])\n",
    "doc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'La fórmula quitará el componente de inflación y se ajustará según la evolución salarial promedio y la recaudación de la Anses, con un tope anual. Un nuevo ataque contra los jubilados que responde a las exigencias del Fondo y el capital financiero.'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc3 = str(list(df[df.flyer == 'JUBILACIONES'].lead)[2])\n",
    "doc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaning(texto):\n",
    "    \n",
    "    import re\n",
    "    import unidecode\n",
    "\n",
    "    stopwords_sp = stopwords.words('spanish')\n",
    "        \n",
    "    alphanumeric = re.sub(r'([^\\s\\w]|_)+', '', texto).lower()\n",
    "    no_accents = unidecode.unidecode(alphanumeric)\n",
    "    \n",
    "    tockens = word_tokenize(no_accents)\n",
    "    \n",
    "    tockens_clean = [tocken for tocken in tockens if tocken not in stopwords_sp]\n",
    "    \n",
    "    terminos = tockens_clean\n",
    "\n",
    "    return terminos\n",
    "\n",
    "t1, t2, t3 = [cleaning(doc) for doc in [doc1, doc2, doc3]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Armo el vocabulario con las palabras de **todo** el corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulario = sorted(set(t1 + t2 + t3)) # sorted transforma el set en list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['12',\n",
       " '5',\n",
       " 'actualizacion',\n",
       " 'acuerdo',\n",
       " 'ahora',\n",
       " 'ajustara',\n",
       " 'ajuste',\n",
       " 'anses',\n",
       " 'anual',\n",
       " 'articulo',\n",
       " 'ataque',\n",
       " 'aumento',\n",
       " 'aumentos',\n",
       " 'buscara',\n",
       " 'cambiar',\n",
       " 'capital',\n",
       " 'completo',\n",
       " 'componente',\n",
       " 'considera',\n",
       " 'cuenta',\n",
       " 'decreto',\n",
       " 'diciembre',\n",
       " 'discrecionales',\n",
       " 'ejecutivo',\n",
       " 'evolucion',\n",
       " 'exigencias',\n",
       " 'explicito',\n",
       " 'financiero',\n",
       " 'fmi',\n",
       " 'fondo',\n",
       " 'formula',\n",
       " 'gobierno',\n",
       " 'haberes',\n",
       " 'implicaron',\n",
       " 'incluye',\n",
       " 'inflacion',\n",
       " 'inflacionario',\n",
       " 'jubilados',\n",
       " 'ley',\n",
       " 'marzo',\n",
       " 'medida',\n",
       " 'meses',\n",
       " 'mira',\n",
       " 'movilidad',\n",
       " 'nueva',\n",
       " 'nuevo',\n",
       " 'otorgado',\n",
       " 'pago',\n",
       " 'previsional',\n",
       " 'promedio',\n",
       " 'proyecto',\n",
       " 'quitar',\n",
       " 'quitara',\n",
       " 'recaudacion',\n",
       " 'reemplazo',\n",
       " 'responde',\n",
       " 'robo',\n",
       " 'salarial',\n",
       " 'segun',\n",
       " 'suspension',\n",
       " 'tope']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulario"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorización de los documentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un documento puede representarse como un vector en el espacio de palabras que conforman el vocabulario. Existen diferentes maneras de definir estos vectores. La más intuitiva es contar el número de veces que aparece cada palabra en un documento y asignarlo como la coordenada o el peso correspondiente a dicha palabra en el vector. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorización manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 61)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textos_procesados = [t1, t2, t3]\n",
    "\n",
    "textos_vocabulario = (len(textos_procesados), len(vocabulario))\n",
    "textos_vocabulario"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La matriz de nros. de palabras del vocabulario por texto rastrea repeticiones.\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "  0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# las filas son la cantidad de textos\n",
    "# las columnas la cantidad de palabras ('ÚNICAS') del vocabulario\n",
    "\n",
    "matriz_ceros = np.zeros(shape = textos_vocabulario, dtype='int')\n",
    "print(f'La matriz de nros. de palabras del vocabulario por texto rastrea repeticiones.\\n{matriz_ceros}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['proyecto',\n",
       "  'ejecutivo',\n",
       "  'nueva',\n",
       "  'ley',\n",
       "  'movilidad',\n",
       "  'previsional',\n",
       "  'incluye',\n",
       "  'articulo',\n",
       "  'considera',\n",
       "  'aumento',\n",
       "  '5',\n",
       "  'otorgado',\n",
       "  'diciembre',\n",
       "  'pago',\n",
       "  'cuenta',\n",
       "  'aumento',\n",
       "  'marzo',\n",
       "  'ajuste',\n",
       "  'explicito',\n",
       "  'medida',\n",
       "  'fmi',\n",
       "  'mira',\n",
       "  'proyecto',\n",
       "  'completo'],\n",
       " ['suspension',\n",
       "  'movilidad',\n",
       "  'previsional',\n",
       "  'reemplazo',\n",
       "  'aumentos',\n",
       "  'discrecionales',\n",
       "  'decreto',\n",
       "  'implicaron',\n",
       "  'robo',\n",
       "  'jubilados',\n",
       "  '12',\n",
       "  'meses',\n",
       "  'ahora',\n",
       "  'gobierno',\n",
       "  'buscara',\n",
       "  'cambiar',\n",
       "  'ley',\n",
       "  'actualizacion',\n",
       "  'haberes',\n",
       "  'acuerdo',\n",
       "  'exigencias',\n",
       "  'fmi',\n",
       "  'quitar',\n",
       "  'componente',\n",
       "  'inflacionario'],\n",
       " ['formula',\n",
       "  'quitara',\n",
       "  'componente',\n",
       "  'inflacion',\n",
       "  'ajustara',\n",
       "  'segun',\n",
       "  'evolucion',\n",
       "  'salarial',\n",
       "  'promedio',\n",
       "  'recaudacion',\n",
       "  'anses',\n",
       "  'tope',\n",
       "  'anual',\n",
       "  'nuevo',\n",
       "  'ataque',\n",
       "  'jubilados',\n",
       "  'responde',\n",
       "  'exigencias',\n",
       "  'fondo',\n",
       "  'capital',\n",
       "  'financiero']]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textos_procesados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se asigna un nro. a cada palabra (su índice en una lista):\n",
      "Texto: 0, Palabra: 50\n",
      "Texto: 0, Palabra: 23\n",
      "Texto: 0, Palabra: 44\n",
      "Texto: 0, Palabra: 38\n",
      "Texto: 0, Palabra: 43\n",
      "Texto: 0, Palabra: 48\n",
      "Texto: 0, Palabra: 34\n",
      "Texto: 0, Palabra: 9\n",
      "Texto: 0, Palabra: 18\n",
      "Texto: 0, Palabra: 11\n",
      "Texto: 0, Palabra: 1\n",
      "Texto: 0, Palabra: 46\n",
      "Texto: 0, Palabra: 21\n",
      "Texto: 0, Palabra: 47\n",
      "Texto: 0, Palabra: 19\n",
      "Texto: 0, Palabra: 11\n",
      "Texto: 0, Palabra: 39\n",
      "Texto: 0, Palabra: 6\n",
      "Texto: 0, Palabra: 26\n",
      "Texto: 0, Palabra: 40\n",
      "Texto: 0, Palabra: 28\n",
      "Texto: 0, Palabra: 42\n",
      "Texto: 0, Palabra: 50\n",
      "Texto: 0, Palabra: 16\n",
      "Texto: 1, Palabra: 59\n",
      "Texto: 1, Palabra: 43\n",
      "Texto: 1, Palabra: 48\n",
      "Texto: 1, Palabra: 54\n",
      "Texto: 1, Palabra: 12\n",
      "Texto: 1, Palabra: 22\n",
      "Texto: 1, Palabra: 20\n",
      "Texto: 1, Palabra: 33\n",
      "Texto: 1, Palabra: 56\n",
      "Texto: 1, Palabra: 37\n",
      "Texto: 1, Palabra: 0\n",
      "Texto: 1, Palabra: 41\n",
      "Texto: 1, Palabra: 4\n",
      "Texto: 1, Palabra: 31\n",
      "Texto: 1, Palabra: 13\n",
      "Texto: 1, Palabra: 14\n",
      "Texto: 1, Palabra: 38\n",
      "Texto: 1, Palabra: 2\n",
      "Texto: 1, Palabra: 32\n",
      "Texto: 1, Palabra: 3\n",
      "Texto: 1, Palabra: 25\n",
      "Texto: 1, Palabra: 28\n",
      "Texto: 1, Palabra: 51\n",
      "Texto: 1, Palabra: 17\n",
      "Texto: 1, Palabra: 36\n",
      "Texto: 2, Palabra: 30\n",
      "Texto: 2, Palabra: 52\n",
      "Texto: 2, Palabra: 17\n",
      "Texto: 2, Palabra: 35\n",
      "Texto: 2, Palabra: 5\n",
      "Texto: 2, Palabra: 58\n",
      "Texto: 2, Palabra: 24\n",
      "Texto: 2, Palabra: 57\n",
      "Texto: 2, Palabra: 49\n",
      "Texto: 2, Palabra: 53\n",
      "Texto: 2, Palabra: 7\n",
      "Texto: 2, Palabra: 60\n",
      "Texto: 2, Palabra: 8\n",
      "Texto: 2, Palabra: 45\n",
      "Texto: 2, Palabra: 10\n",
      "Texto: 2, Palabra: 37\n",
      "Texto: 2, Palabra: 55\n",
      "Texto: 2, Palabra: 25\n",
      "Texto: 2, Palabra: 29\n",
      "Texto: 2, Palabra: 15\n",
      "Texto: 2, Palabra: 27\n"
     ]
    }
   ],
   "source": [
    "print('Se asigna un nro. a cada palabra (su índice en una lista):')\n",
    "for i, texto in enumerate(textos_procesados):\n",
    "    for palabra in texto:\n",
    "        print(f'Texto: {i}, Palabra: {vocabulario.index(palabra)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 2, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
       "        0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1,\n",
       "        1, 0, 1, 1, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0,\n",
       "        1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1,\n",
       "        0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i, texto in enumerate(textos_procesados):\n",
    "    for palabra in texto:\n",
    "        matriz_ceros[i, vocabulario.index(palabra)] +=1\n",
    "\n",
    "matriz_ceros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armo matriz con las palabras\n",
    "# El nro. de columnas de la matriz equivale a la cantidad ade palabras del vocabulario\n",
    "\n",
    "data_vectorizada = pd.DataFrame(matriz_ceros, columns = vocabulario, index=['Texto ' + str(i) for i in range(len(textos_procesados))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>12</th>\n",
       "      <th>5</th>\n",
       "      <th>actualizacion</th>\n",
       "      <th>acuerdo</th>\n",
       "      <th>ahora</th>\n",
       "      <th>ajustara</th>\n",
       "      <th>ajuste</th>\n",
       "      <th>anses</th>\n",
       "      <th>anual</th>\n",
       "      <th>articulo</th>\n",
       "      <th>...</th>\n",
       "      <th>quitar</th>\n",
       "      <th>quitara</th>\n",
       "      <th>recaudacion</th>\n",
       "      <th>reemplazo</th>\n",
       "      <th>responde</th>\n",
       "      <th>robo</th>\n",
       "      <th>salarial</th>\n",
       "      <th>segun</th>\n",
       "      <th>suspension</th>\n",
       "      <th>tope</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Texto 0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texto 1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Texto 2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 61 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         12  5  actualizacion  acuerdo  ahora  ajustara  ajuste  anses  anual  \\\n",
       "Texto 0   0  1              0        0      0         0       1      0      0   \n",
       "Texto 1   1  0              1        1      1         0       0      0      0   \n",
       "Texto 2   0  0              0        0      0         1       0      1      1   \n",
       "\n",
       "         articulo  ...  quitar  quitara  recaudacion  reemplazo  responde  \\\n",
       "Texto 0         1  ...       0        0            0          0         0   \n",
       "Texto 1         0  ...       1        0            0          1         0   \n",
       "Texto 2         0  ...       0        1            1          0         1   \n",
       "\n",
       "         robo  salarial  segun  suspension  tope  \n",
       "Texto 0     0         0      0           0     0  \n",
       "Texto 1     1         0      0           1     0  \n",
       "Texto 2     0         1      1           0     1  \n",
       "\n",
       "[3 rows x 61 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_vectorizada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorización automática\n",
    "(CountVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "INFORME INDEC        7\n",
       "ACTUALIDAD           6\n",
       "ENDEUDAMIENTO        4\n",
       "TIPO DE CAMBIO       4\n",
       "AJUSTE               3\n",
       "TENSION CAMBIARIA    3\n",
       "JUBILACIONES         3\n",
       "ALERTA SPOILER       3\n",
       "DEUDA EXTERNA        3\n",
       "CRISIS ECONOMICA     3\n",
       "Name: flyer, dtype: int64"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.flyer.value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4 = list(df[df.flyer == 'DEUDA EXTERNA'].lead)[0]\n",
    "doc5 = list(df[df.flyer == 'DEUDA EXTERNA'].lead)[1]\n",
    "doc6 = list(df[df.flyer == 'DEUDA EXTERNA'].lead)[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 -> El proyecto del Ejecutivo para una nueva ley de movilidad previsional incluye un artículo que considera el aumento del 5 % otorgado en diciembre como un pago a cuenta del aumento de marzo. Ajuste explícito a la medida del FMI. Mirá el proyecto completo.\n",
      "\n",
      "2 -> La suspensión de la movilidad previsional y su reemplazo por aumentos discrecionales por decreto implicaron un robo a los jubilados en estos 12 meses. Ahora el Gobierno buscará cambiar la ley de actualización de haberes de acuerdo a las exigencias del FMI de quitar el componente inflacionario.\n",
      "\n",
      "3 -> La fórmula quitará el componente de inflación y se ajustará según la evolución salarial promedio y la recaudación de la Anses, con un tope anual. Un nuevo ataque contra los jubilados que responde a las exigencias del Fondo y el capital financiero.\n",
      "\n",
      "4 -> El Ministerio de Economía informó el canje de 43.038 millones de títulos de deuda en pesos por dos bonos nominados en dólares por USD 750 millones. En diciembre se repite la operatoria con una nueva licitación en dólares.\n",
      "\n",
      "5 -> Es el tipo de préstamo que solicitó el Gobierno para refinanciar la deuda contraída bajo el macrismo con el organismo. Tiene un plazo de hasta diez años e implicaría condiciones más estrictas que pueden incluir reformas estructurales.\n",
      "\n",
      "6 -> De ser aprobada, la ley, todos los préstamos en divisas extranjeras deberán tener previamente el visto bueno del Parlamento. Un nuevo mecanismo para alinear a los partidos detrás de los mandatos del Fondo.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "corpus = [doc1, doc2, doc3, doc4, doc5, doc6]\n",
    "for i, doc in enumerate(corpus):\n",
    "    print(f'{i+1} -> {doc}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizador = CountVectorizer(stop_words = stopwords_sp, lowercase = True, strip_accents='unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guido/anaconda3/envs/dh/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'proyecto': 92,\n",
       " 'ejecutivo': 42,\n",
       " 'nueva': 77,\n",
       " 'ley': 63,\n",
       " 'movilidad': 75,\n",
       " 'previsional': 90,\n",
       " 'incluye': 58,\n",
       " 'articulo': 14,\n",
       " 'considera': 28,\n",
       " 'aumento': 16,\n",
       " 'otorgado': 81,\n",
       " 'diciembre': 35,\n",
       " 'pago': 82,\n",
       " 'cuenta': 30,\n",
       " 'marzo': 67,\n",
       " 'ajuste': 8,\n",
       " 'explicito': 47,\n",
       " 'medida': 70,\n",
       " 'fmi': 50,\n",
       " 'mira': 74,\n",
       " 'completo': 25,\n",
       " 'suspension': 107,\n",
       " 'reemplazo': 97,\n",
       " 'aumentos': 17,\n",
       " 'discrecionales': 37,\n",
       " 'decreto': 32,\n",
       " 'implicaron': 56,\n",
       " 'robo': 102,\n",
       " 'jubilados': 62,\n",
       " '12': 1,\n",
       " 'meses': 71,\n",
       " 'ahora': 6,\n",
       " 'gobierno': 53,\n",
       " 'buscara': 21,\n",
       " 'cambiar': 22,\n",
       " 'actualizacion': 4,\n",
       " 'haberes': 54,\n",
       " 'acuerdo': 5,\n",
       " 'exigencias': 46,\n",
       " 'quitar': 94,\n",
       " 'componente': 26,\n",
       " 'inflacionario': 60,\n",
       " 'formula': 52,\n",
       " 'quitara': 95,\n",
       " 'inflacion': 59,\n",
       " 'ajustara': 7,\n",
       " 'segun': 104,\n",
       " 'evolucion': 45,\n",
       " 'salarial': 103,\n",
       " 'promedio': 91,\n",
       " 'recaudacion': 96,\n",
       " 'anses': 11,\n",
       " 'tope': 111,\n",
       " 'anual': 12,\n",
       " 'nuevo': 78,\n",
       " 'ataque': 15,\n",
       " 'responde': 101,\n",
       " 'fondo': 51,\n",
       " 'capital': 24,\n",
       " 'financiero': 49,\n",
       " 'ministerio': 73,\n",
       " 'economia': 41,\n",
       " 'informo': 61,\n",
       " 'canje': 23,\n",
       " '43': 2,\n",
       " '038': 0,\n",
       " 'millones': 72,\n",
       " 'titulos': 110,\n",
       " 'deuda': 34,\n",
       " 'pesos': 85,\n",
       " 'dos': 40,\n",
       " 'bonos': 19,\n",
       " 'nominados': 76,\n",
       " 'dolares': 39,\n",
       " 'usd': 112,\n",
       " '750': 3,\n",
       " 'repite': 100,\n",
       " 'operatoria': 79,\n",
       " 'licitacion': 64,\n",
       " 'tipo': 109,\n",
       " 'prestamo': 87,\n",
       " 'solicito': 106,\n",
       " 'refinanciar': 98,\n",
       " 'contraida': 29,\n",
       " 'bajo': 18,\n",
       " 'macrismo': 65,\n",
       " 'organismo': 80,\n",
       " 'plazo': 86,\n",
       " 'diez': 36,\n",
       " 'anos': 10,\n",
       " 'implicaria': 55,\n",
       " 'condiciones': 27,\n",
       " 'mas': 68,\n",
       " 'estrictas': 43,\n",
       " 'pueden': 93,\n",
       " 'incluir': 57,\n",
       " 'reformas': 99,\n",
       " 'estructurales': 44,\n",
       " 'ser': 105,\n",
       " 'aprobada': 13,\n",
       " 'prestamos': 88,\n",
       " 'divisas': 38,\n",
       " 'extranjeras': 48,\n",
       " 'deberan': 31,\n",
       " 'tener': 108,\n",
       " 'previamente': 89,\n",
       " 'visto': 113,\n",
       " 'bueno': 20,\n",
       " 'parlamento': 83,\n",
       " 'mecanismo': 69,\n",
       " 'alinear': 9,\n",
       " 'partidos': 84,\n",
       " 'detras': 33,\n",
       " 'mandatos': 66}"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizador.fit(corpus)\n",
    "vectorizador.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado de la codificación es una matriz dispersa (donde predominan los ceros) o \"sparse matrix\" *comprimida* (sin los ceros)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6x114 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 128 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matriz_dispersa_comprimida = vectorizador.transform(corpus)\n",
    "matriz_dispersa_comprimida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 8)\t1\n",
      "  (0, 14)\t1\n",
      "  (0, 16)\t2\n",
      "  (0, 25)\t1\n",
      "  (0, 28)\t1\n",
      "  (0, 30)\t1\n",
      "  (0, 35)\t1\n",
      "  (0, 42)\t1\n",
      "  (0, 47)\t1\n",
      "  (0, 50)\t1\n",
      "  (0, 58)\t1\n",
      "  (0, 63)\t1\n",
      "  (0, 67)\t1\n",
      "  (0, 70)\t1\n",
      "  (0, 74)\t1\n",
      "  (0, 75)\t1\n",
      "  (0, 77)\t1\n",
      "  (0, 81)\t1\n",
      "  (0, 82)\t1\n",
      "  (0, 90)\t1\n",
      "  (0, 92)\t2\n",
      "  (1, 1)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 5)\t1\n",
      "  (1, 6)\t1\n",
      "  :\t:\n",
      "  (4, 87)\t1\n",
      "  (4, 93)\t1\n",
      "  (4, 98)\t1\n",
      "  (4, 99)\t1\n",
      "  (4, 106)\t1\n",
      "  (4, 109)\t1\n",
      "  (5, 9)\t1\n",
      "  (5, 13)\t1\n",
      "  (5, 20)\t1\n",
      "  (5, 31)\t1\n",
      "  (5, 33)\t1\n",
      "  (5, 38)\t1\n",
      "  (5, 48)\t1\n",
      "  (5, 51)\t1\n",
      "  (5, 63)\t1\n",
      "  (5, 66)\t1\n",
      "  (5, 69)\t1\n",
      "  (5, 78)\t1\n",
      "  (5, 83)\t1\n",
      "  (5, 84)\t1\n",
      "  (5, 88)\t1\n",
      "  (5, 89)\t1\n",
      "  (5, 105)\t1\n",
      "  (5, 108)\t1\n",
      "  (5, 113)\t1\n"
     ]
    }
   ],
   "source": [
    "print(matriz_dispersa_comprimida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "         1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "         1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0,\n",
       "         0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "         1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "         1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0,\n",
       "         0, 0, 1, 0, 0, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
       "         0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "        [1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "         0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 2, 1, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0,\n",
       "         0, 1, 0, 0, 0, 0, 0, 0, 0, 2, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "         0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 1, 0, 1, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "         0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "         0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "         0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0,\n",
       "         0, 1, 0, 0, 1, 0, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "         0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1,\n",
       "         1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "         1, 0, 0, 1, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matriz_dispersa = matriz_dispersa_comprimida.todense()\n",
    "matriz_dispersa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['038',\n",
       " '12',\n",
       " '43',\n",
       " '750',\n",
       " 'actualizacion',\n",
       " 'acuerdo',\n",
       " 'ahora',\n",
       " 'ajustara',\n",
       " 'ajuste',\n",
       " 'alinear']"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizador.get_feature_names()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>038</th>\n",
       "      <th>12</th>\n",
       "      <th>43</th>\n",
       "      <th>750</th>\n",
       "      <th>actualizacion</th>\n",
       "      <th>acuerdo</th>\n",
       "      <th>ahora</th>\n",
       "      <th>ajustara</th>\n",
       "      <th>ajuste</th>\n",
       "      <th>alinear</th>\n",
       "      <th>...</th>\n",
       "      <th>segun</th>\n",
       "      <th>ser</th>\n",
       "      <th>solicito</th>\n",
       "      <th>suspension</th>\n",
       "      <th>tener</th>\n",
       "      <th>tipo</th>\n",
       "      <th>titulos</th>\n",
       "      <th>tope</th>\n",
       "      <th>usd</th>\n",
       "      <th>visto</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 114 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   038  12  43  750  actualizacion  acuerdo  ahora  ajustara  ajuste  alinear  \\\n",
       "0    0   0   0    0              0        0      0         0       1        0   \n",
       "1    0   1   0    0              1        1      1         0       0        0   \n",
       "2    0   0   0    0              0        0      0         1       0        0   \n",
       "3    1   0   1    1              0        0      0         0       0        0   \n",
       "4    0   0   0    0              0        0      0         0       0        0   \n",
       "5    0   0   0    0              0        0      0         0       0        1   \n",
       "\n",
       "   ...  segun  ser  solicito  suspension  tener  tipo  titulos  tope  usd  \\\n",
       "0  ...      0    0         0           0      0     0        0     0    0   \n",
       "1  ...      0    0         0           1      0     0        0     0    0   \n",
       "2  ...      1    0         0           0      0     0        0     1    0   \n",
       "3  ...      0    0         0           0      0     0        1     0    1   \n",
       "4  ...      0    0         1           0      0     1        0     0    0   \n",
       "5  ...      0    1         0           0      1     0        0     0    0   \n",
       "\n",
       "   visto  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  \n",
       "5      1  \n",
       "\n",
       "[6 rows x 114 columns]"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(matriz_dispersa, columns = vectorizador.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Métricas y Vectorización\n",
    "#### **Term Frequency Inverse Document Frequency (TF-IDF)**\n",
    "\n",
    "Estadístico numérico fundamental para reflejar cuán relevante es un término para un documento en un corpus o conjunto de documentos.\n",
    "\n",
    "1. **Normalizar** -> dividir el conteo de cada palabra por el total de palabras del documento.\n",
    "\n",
    "2. Relevar **Palabras Informativas** -> frecuencia de la palabra VS frecuencia del documento donde figura esa palabra respecto a la totalidad de documentos (corpus)\n",
    "\n",
    "Una palabra que aparece muchas veces en un documento, pero pocas veces en los demás, es una palabra muy distintiva de ese documento y será importante para representarlo, mientras que palabras que aparecen pocas veces, o que aparecen en muchos documentos, serán menos informativas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF permite encontrar las palabras informativas distintivas de cada documento y su peso en el copus.\n",
    "\n",
    "\\begin{equation}\n",
    " \\text{tf - idf}(t,d)=\\text{tf}(t,d) \\times idf(t)\n",
    "\\end{equation}\n",
    "\n",
    "- **tf(t,d)** es la frecuencia (normalizada) de aparición de t dentro de d.\n",
    "- **idf(t)** es la *inverse document frecuency* del término t.\n",
    "\n",
    "\\begin{equation}\n",
    "    \\text{id}f(t)=\\log{\\frac{N}{\\text{df(t)+1}}} \n",
    "\\end{equation}\n",
    "\n",
    "- **N** es el número de documentos.\n",
    "- **df(t)** es el número de documentos en los que aparece el término t (se suma 1 por si aparece un término en el vocabulario que no aparece en ningún documento *df = 0*).\n",
    "\n",
    "\\begin{equation}\n",
    " \\text{tf - idf}(t,d)=\\text{tf}(t,d) \\times log{\\frac{N}{\\text{df(t)+1}}} \n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplo**\n",
    "\n",
    "doc1 = 'El proyecto del Ejecutivo para una nueva ley de movilidad previsional incluye un artículo que considera el aumento del 5 % otorgado en diciembre como un pago a cuenta del aumento de marzo. Ajuste explícito a la medida del FMI. Mirá el proyecto completo.'\n",
    "\n",
    "doc2 = 'La suspensión de la movilidad previsional y su reemplazo por aumentos discrecionales por decreto implicaron un robo a los jubilados en estos 12 meses. Ahora el Gobierno buscará cambiar la ley de actualización de haberes de acuerdo a las exigencias del FMI de quitar el componente inflacionario.'\n",
    "\n",
    "doc3 = 'La fórmula quitará el componente de inflación y se ajustará según la evolución salarial promedio y la recaudación de la Anses, con un tope anual. Un nuevo ataque contra los jubilados que responde a las exigencias del Fondo y el capital financiero.'\n",
    "\n",
    "doc4 = El Ministerio de Economía informó el canje de 43.038 millones de títulos de deuda en pesos por dos bonos nominados en dólares por USD 750 millones. En diciembre se repite la operatoria con una nueva licitación en dólares.\n",
    "\n",
    "doc5 = Es el tipo de préstamo que solicitó el Gobierno para refinanciar la deuda contraída bajo el macrismo con el organismo. Tiene un plazo de hasta diez años e implicaría condiciones más estrictas que pueden incluir reformas estructurales.\n",
    "\n",
    "doc6 = De ser aprobada, la ley, todos los préstamos en divisas extranjeras deberán tener previamente el visto bueno del Parlamento. Un nuevo mecanismo para alinear a los partidos detrás de los mandatos del Fondo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Term Frequency**\n",
    "\n",
    "tf('FMI', doc1) = 1 / 43 = 0.023\n",
    "\n",
    "tf('FMI', doc2) = 1 / 47 = 0.021\n",
    "\n",
    "tf('FMI', doc3) = 1 / 42 = 0.024\n",
    "\n",
    "tf('FMI', doc4) = 0 / 38 = 0\n",
    "\n",
    "tf('FMI', doc5) = 0 / 37 = 0\n",
    "\n",
    "tf('FMI', doc6) = 1 / 33 = 0.030\n",
    "\n",
    "**Inverse Document Frequency**\n",
    "\n",
    "idf('FMI') = log [6 / (4 + 1)] = 0.079\n",
    "\n",
    "**Coefficient**\n",
    "\n",
    "tf - idf('FMI', doc1) = 0.023 * 0.079 = 0.0018\n",
    "\n",
    "VS\n",
    "\n",
    "tf - idf('previsional', doc1) = 0.023 * log [6 / (2 + 1)] = 0.3010\n",
    "\n",
    "El coeficiente de \"previsional\" es mayor al de 'FMI' por aparecer en menos documentos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TfidfVectorizer, TfidfTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TfidfVectorizer y TfidfTransformer permiten calcular una *versión ponderada* del **idf**\n",
    "\n",
    "\\begin{equation}\n",
    "    \\text{idf(t)}= \\log{\\frac{N+1}{df(t)+1}}+1\n",
    "\\end{equation}\n",
    "\n",
    "normalizando luego los documentos vectorizados por su norma Euclidiana L2.<br>\n",
    "https://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sin normalizar\n",
    "matriz_dispersa_comprimida_Tfidf_1 = TfidfTransformer(norm='l1', use_idf=True, smooth_idf=False).fit_transform(matriz_dispersa);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 92)\t0.4012747576340004\n",
      "  (0, 90)\t0.16452552078743182\n",
      "  (0, 82)\t0.2006373788170002\n",
      "  (0, 81)\t0.2006373788170002\n",
      "  (0, 77)\t0.16452552078743182\n",
      "  (0, 75)\t0.16452552078743182\n",
      "  (0, 74)\t0.2006373788170002\n",
      "  (0, 70)\t0.2006373788170002\n",
      "  (0, 67)\t0.2006373788170002\n",
      "  (0, 63)\t0.13890374976377237\n",
      "  (0, 58)\t0.2006373788170002\n",
      "  (0, 50)\t0.16452552078743182\n",
      "  (0, 47)\t0.2006373788170002\n",
      "  (0, 42)\t0.2006373788170002\n",
      "  (0, 35)\t0.16452552078743182\n",
      "  (0, 30)\t0.2006373788170002\n",
      "  (0, 28)\t0.2006373788170002\n",
      "  (0, 25)\t0.2006373788170002\n",
      "  (0, 16)\t0.4012747576340004\n",
      "  (0, 14)\t0.2006373788170002\n",
      "  (0, 8)\t0.2006373788170002\n",
      "  (1, 107)\t0.21230388618186638\n",
      "  (1, 102)\t0.21230388618186638\n",
      "  (1, 97)\t0.21230388618186638\n",
      "  (1, 94)\t0.21230388618186638\n",
      "  :\t:\n",
      "  (4, 36)\t0.22170362121419707\n",
      "  (4, 34)\t0.18180014090990831\n",
      "  (4, 29)\t0.22170362121419707\n",
      "  (4, 27)\t0.22170362121419707\n",
      "  (4, 18)\t0.22170362121419707\n",
      "  (4, 10)\t0.22170362121419707\n",
      "  (5, 113)\t0.23686214947564455\n",
      "  (5, 108)\t0.23686214947564455\n",
      "  (5, 105)\t0.23686214947564455\n",
      "  (5, 89)\t0.23686214947564455\n",
      "  (5, 88)\t0.23686214947564455\n",
      "  (5, 84)\t0.23686214947564455\n",
      "  (5, 83)\t0.23686214947564455\n",
      "  (5, 78)\t0.19423035093004806\n",
      "  (5, 69)\t0.23686214947564455\n",
      "  (5, 66)\t0.23686214947564455\n",
      "  (5, 63)\t0.16398260849132684\n",
      "  (5, 51)\t0.19423035093004806\n",
      "  (5, 48)\t0.23686214947564455\n",
      "  (5, 38)\t0.23686214947564455\n",
      "  (5, 33)\t0.23686214947564455\n",
      "  (5, 31)\t0.23686214947564455\n",
      "  (5, 20)\t0.23686214947564455\n",
      "  (5, 13)\t0.23686214947564455\n",
      "  (5, 9)\t0.23686214947564455\n"
     ]
    }
   ],
   "source": [
    "# normalizado\n",
    "matriz_dispersa_comprimida_Tfidf_2 = TfidfTransformer(norm='l2', use_idf=True, smooth_idf=True).fit_transform(matriz_dispersa);\n",
    "print(matriz_dispersa_comprimida_Tfidf_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.20063738, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.20063738,\n",
       "         0.        , 0.40127476, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.20063738, 0.        , 0.        , 0.20063738, 0.        ,\n",
       "         0.20063738, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.16452552, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.20063738, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.20063738, 0.        , 0.        ,\n",
       "         0.16452552, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.20063738, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.13890375, 0.        ,\n",
       "         0.        , 0.        , 0.20063738, 0.        , 0.        ,\n",
       "         0.20063738, 0.        , 0.        , 0.        , 0.20063738,\n",
       "         0.16452552, 0.        , 0.16452552, 0.        , 0.        ,\n",
       "         0.        , 0.20063738, 0.20063738, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.16452552, 0.        , 0.40127476, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.21230389, 0.        , 0.        , 0.21230389,\n",
       "         0.21230389, 0.21230389, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.21230389, 0.        , 0.        ,\n",
       "         0.        , 0.21230389, 0.21230389, 0.        , 0.        ,\n",
       "         0.        , 0.17409222, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.21230389, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.21230389, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.17409222, 0.        , 0.        , 0.        ,\n",
       "         0.17409222, 0.        , 0.        , 0.17409222, 0.21230389,\n",
       "         0.        , 0.21230389, 0.        , 0.        , 0.        ,\n",
       "         0.21230389, 0.        , 0.17409222, 0.14698062, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.21230389, 0.        , 0.        , 0.        ,\n",
       "         0.17409222, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.17409222, 0.        , 0.        , 0.        , 0.21230389,\n",
       "         0.        , 0.        , 0.21230389, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.21230389, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.21230389, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.2272603 , 0.        , 0.        ,\n",
       "         0.        , 0.2272603 , 0.2272603 , 0.        , 0.        ,\n",
       "         0.2272603 , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.2272603 ,\n",
       "         0.        , 0.1863567 , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.2272603 , 0.1863567 , 0.        , 0.        , 0.2272603 ,\n",
       "         0.        , 0.1863567 , 0.2272603 , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.2272603 ,\n",
       "         0.        , 0.        , 0.1863567 , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.1863567 , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.2272603 , 0.        , 0.        , 0.        ,\n",
       "         0.2272603 , 0.2272603 , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.2272603 , 0.        , 0.2272603 , 0.2272603 ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.2272603 , 0.        , 0.        ],\n",
       "        [0.19605103, 0.        , 0.19605103, 0.19605103, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.19605103,\n",
       "         0.        , 0.        , 0.        , 0.19605103, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.16076465,\n",
       "         0.16076465, 0.        , 0.        , 0.        , 0.39210207,\n",
       "         0.19605103, 0.19605103, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.19605103, 0.        , 0.        , 0.19605103,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.39210207, 0.19605103, 0.        ,\n",
       "         0.        , 0.19605103, 0.16076465, 0.        , 0.19605103,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.19605103, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.19605103, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.19605103, 0.        , 0.19605103, 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.22170362, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.22170362, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.22170362, 0.        , 0.22170362,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.18180014,\n",
       "         0.        , 0.22170362, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.22170362, 0.22170362,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.18180014, 0.        ,\n",
       "         0.22170362, 0.        , 0.22170362, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.22170362, 0.        , 0.        , 0.22170362, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.22170362, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.22170362, 0.22170362, 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.22170362, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.22170362, 0.22170362,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.22170362, 0.        , 0.        , 0.22170362,\n",
       "         0.        , 0.        , 0.        , 0.        ],\n",
       "        [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.23686215,\n",
       "         0.        , 0.        , 0.        , 0.23686215, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.23686215, 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.23686215, 0.        , 0.23686215, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.23686215, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.23686215, 0.        ,\n",
       "         0.        , 0.19423035, 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.16398261, 0.        ,\n",
       "         0.        , 0.23686215, 0.        , 0.        , 0.23686215,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.19423035, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.23686215, 0.23686215,\n",
       "         0.        , 0.        , 0.        , 0.23686215, 0.23686215,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "         0.23686215, 0.        , 0.        , 0.23686215, 0.        ,\n",
       "         0.        , 0.        , 0.        , 0.23686215]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "matriz_cod_Tfidf = matriz_dispersa_comprimida_Tfidf_2.todense()\n",
    "display(matriz_cod_Tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Singular Value Decomposition (SVD)\n",
    "*de las palabras a las combinaciones lineales informativas*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El objetivo de la transformación algebraica de nombre SVD consiste en encontrar **combinaciones lineales de los términos** que resulten **informativas** a fin de describir el corpus con un número de combinaciones menor al número de términos original. Estas **combinaciones** pueden considerarse como **dimensiones con *sentido semántico latente* (latent semantic dimensions)**.\n",
    "\n",
    "El motivo por el cual podemos reducir la dimensionalidad de los textos proyectandolos a estas *latent semantic dimensions* es que **muchas veces existe redundancia en el conjunto de documentos (dentro del corpus)**. Es decir que con palabras más o menos distintas, muchos documentos hablan de los mismos temas.\n",
    "\n",
    "Esta reducción de la dimensionalidad podría mejorar la performance de un clasificador o un modelo de clustering. Por otro lado, una reducción a dos o tres dimensiones nos puede permitir visualizar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.507  0.45 ]\n",
      " [ 0.673  0.033]\n",
      " [ 0.524 -0.475]\n",
      " [ 0.177  0.591]\n",
      " [ 0.15   0.325]\n",
      " [ 0.372 -0.415]]\n"
     ]
    }
   ],
   "source": [
    "# n_components = Desired dimensionality of output data. \n",
    "# Must be strictly less than the number of features.\n",
    "svd = TruncatedSVD(n_components = 2)\n",
    "P = svd.fit_transform(matriz_dispersa_comprimida_Tfidf_2)\n",
    "print(np.around(P,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.50672412  0.44985021]\n",
      " [ 0.67260367  0.03320242]\n",
      " [ 0.52408857 -0.47535139]\n",
      " [ 0.17685159  0.59097544]\n",
      " [ 0.15001323  0.32517542]\n",
      " [ 0.37248954 -0.41464616]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(P)\n",
    "#grafico\n",
    "color = ['m', 'g', 'r', 'c', 'b','k']\n",
    "plt.figure()\n",
    "patches = []\n",
    "\n",
    "for i,texto in enumerate(corpus):\n",
    "    plt.plot(P[i,0], P[i,1], color[i]+\"o\")\n",
    "    patches.append(mpatches.Patch(color=color[i], label='t'+str(i)))\n",
    "\n",
    "plt.legend(handles=patches)\n",
    "plt.xlabel('dimension 1')\n",
    "plt.ylabel('dimension 2')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.02947385  0.12138804  0.02947385  0.02947385  0.12138804  0.12138804\n",
      "   0.12138804  0.10124813  0.08642555  0.07500125  0.0282723   0.10124813\n",
      "   0.10124813  0.07500125  0.08642555  0.10124813  0.1728511   0.12138804\n",
      "   0.0282723   0.02947385  0.07500125  0.12138804  0.12138804  0.02947385\n",
      "   0.10124813  0.08642555  0.18256484  0.0282723   0.08642555  0.0282723\n",
      "   0.08642555  0.07500125  0.12138804  0.07500125  0.04735266  0.09503916\n",
      "   0.0282723   0.12138804  0.07500125  0.05894769  0.02947385  0.02947385\n",
      "   0.08642555  0.0282723   0.0282723   0.10124813  0.18256484  0.08642555\n",
      "   0.07500125  0.10124813  0.17041012  0.14452701  0.10124813  0.12272362\n",
      "   0.12138804  0.0282723   0.12138804  0.0282723   0.08642555  0.10124813\n",
      "   0.12138804  0.02947385  0.18256484  0.19579623  0.02947385  0.0282723\n",
      "   0.07500125  0.08642555  0.0282723   0.07500125  0.08642555  0.12138804\n",
      "   0.05894769  0.02947385  0.08642555  0.17041012  0.02947385  0.09503916\n",
      "   0.14452701  0.02947385  0.0282723   0.08642555  0.08642555  0.07500125\n",
      "   0.07500125  0.02947385  0.0282723   0.0282723   0.07500125  0.07500125\n",
      "   0.17041012  0.10124813  0.1728511   0.0282723   0.12138804  0.10124813\n",
      "   0.10124813  0.12138804  0.0282723   0.0282723   0.02947385  0.10124813\n",
      "   0.12138804  0.10124813  0.10124813  0.07500125  0.0282723   0.12138804\n",
      "   0.07500125  0.0282723   0.02947385  0.10124813  0.02947385  0.07500125]\n",
      " [ 0.10968093  0.00667299  0.10968093  0.10968093  0.00667299  0.00667299\n",
      "   0.00667299 -0.10226591  0.08544218 -0.09297494  0.06824692 -0.10226591\n",
      "  -0.10226591 -0.09297494  0.08544218 -0.10226591  0.17088437  0.00667299\n",
      "   0.06824692  0.10968093 -0.09297494  0.00667299  0.00667299  0.10968093\n",
      "  -0.10226591  0.08544218 -0.07838757  0.06824692  0.08544218  0.06824692\n",
      "   0.08544218 -0.09297494  0.00667299 -0.09297494  0.14590338  0.16000375\n",
      "   0.06824692  0.00667299 -0.09297494  0.21936187  0.10968093  0.10968093\n",
      "   0.08544218  0.06824692  0.06824692 -0.10226591 -0.07838757  0.08544218\n",
      "  -0.09297494 -0.10226591  0.07553576 -0.16010029 -0.10226591  0.0614354\n",
      "   0.00667299  0.06824692  0.00667299  0.06824692  0.08544218 -0.10226591\n",
      "   0.00667299  0.10968093 -0.07838757 -0.00059523  0.10968093  0.06824692\n",
      "  -0.09297494  0.08544218  0.06824692 -0.09297494  0.08544218  0.00667299\n",
      "   0.21936187  0.10968093  0.08544218  0.07553576  0.10968093  0.16000375\n",
      "  -0.16010029  0.10968093  0.06824692  0.08544218  0.08544218 -0.09297494\n",
      "  -0.09297494  0.10968093  0.06824692  0.06824692 -0.09297494 -0.09297494\n",
      "   0.07553576 -0.10226591  0.17088437  0.06824692  0.00667299 -0.10226591\n",
      "  -0.10226591  0.00667299  0.06824692  0.06824692  0.10968093 -0.10226591\n",
      "   0.00667299 -0.10226591 -0.10226591 -0.09297494  0.06824692  0.00667299\n",
      "  -0.09297494  0.06824692  0.10968093 -0.10226591  0.10968093 -0.09297494]]\n"
     ]
    }
   ],
   "source": [
    "# coeficientes (pesos) de los términos en cada una de las dos dimensiones\n",
    "comp1, comp2 = svd.components_ \n",
    "print(svd.components_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension 1:\n",
      "['ley' 'componente' 'exigencias' 'jubilados' 'aumento' 'proyecto'\n",
      " 'movilidad' 'previsional' 'fmi' 'fondo' 'nuevo' 'gobierno' 'haberes'\n",
      " 'cambiar' 'buscara' 'meses' 'aumentos' 'decreto' 'inflacionario'\n",
      " 'implicaron' 'discrecionales' 'reemplazo' 'suspension' 'acuerdo' 'robo'\n",
      " 'quitar' 'ahora' 'actualizacion' '12' 'tope' 'anual' 'formula' 'promedio'\n",
      " 'quitara' 'inflacion' 'segun' 'salarial' 'capital' 'responde' 'anses'\n",
      " 'ajustara' 'financiero' 'ataque' 'evolucion' 'recaudacion' 'diciembre'\n",
      " 'nueva' 'ajuste' 'pago' 'otorgado' 'articulo' 'cuenta' 'considera'\n",
      " 'incluye' 'completo' 'medida' 'ejecutivo' 'mira' 'explicito' 'marzo'\n",
      " 'extranjeras' 'detras' 'deberan' 'alinear' 'tener' 'ser' 'mecanismo'\n",
      " 'bueno' 'divisas' 'parlamento' 'partidos' 'aprobada' 'prestamos'\n",
      " 'previamente' 'mandatos' 'visto' 'dolares' 'millones' 'deuda' '43'\n",
      " 'operatoria' 'ministerio' 'canje' 'licitacion' 'informo' 'nominados'\n",
      " 'pesos' 'repite' 'titulos' 'economia' 'dos' 'bonos' 'usd' '038' '750'\n",
      " 'mas' 'diez' 'estrictas' 'estructurales' 'tipo' 'solicito' 'implicaria'\n",
      " 'reformas' 'refinanciar' 'pueden' 'anos' 'prestamo' 'plazo' 'contraida'\n",
      " 'organismo' 'condiciones' 'incluir' 'macrismo' 'bajo']\n",
      "\n",
      "\n",
      "Dimension 2:\n",
      "['dolares' 'millones' 'proyecto' 'aumento' 'nueva' 'diciembre' 'deuda'\n",
      " '038' '43' 'pesos' 'nominados' 'canje' 'ministerio' 'bonos' 'licitacion'\n",
      " 'repite' 'informo' 'usd' 'dos' 'economia' 'titulos' 'operatoria' '750'\n",
      " 'otorgado' 'marzo' 'cuenta' 'medida' 'incluye' 'mira' 'ejecutivo'\n",
      " 'considera' 'explicito' 'pago' 'completo' 'ajuste' 'articulo' 'fmi'\n",
      " 'movilidad' 'previsional' 'estructurales' 'estrictas' 'tipo' 'solicito'\n",
      " 'implicaria' 'incluir' 'diez' 'anos' 'reformas' 'refinanciar' 'macrismo'\n",
      " 'pueden' 'condiciones' 'plazo' 'prestamo' 'contraida' 'organismo' 'bajo'\n",
      " 'mas' 'gobierno' '12' 'acuerdo' 'discrecionales' 'ahora' 'decreto'\n",
      " 'cambiar' 'aumentos' 'buscara' 'implicaron' 'suspension' 'meses'\n",
      " 'haberes' 'quitar' 'robo' 'inflacionario' 'reemplazo' 'actualizacion'\n",
      " 'ley' 'jubilados' 'exigencias' 'componente' 'visto' 'aprobada' 'partidos'\n",
      " 'alinear' 'bueno' 'ser' 'tener' 'prestamos' 'previamente' 'divisas'\n",
      " 'extranjeras' 'mecanismo' 'deberan' 'mandatos' 'detras' 'parlamento'\n",
      " 'capital' 'tope' 'financiero' 'formula' 'segun' 'ajustara' 'salarial'\n",
      " 'anual' 'inflacion' 'anses' 'responde' 'ataque' 'recaudacion' 'quitara'\n",
      " 'promedio' 'evolucion' 'fondo' 'nuevo']\n"
     ]
    }
   ],
   "source": [
    "# los ordenamos de menor a mayor y nos quedamos con los índices de sus posiciones en el array\n",
    "indices = np.argsort(comp1) \n",
    "# invertimos para que queden ordenados de mayor a menor\n",
    "indices = indices[::-1]\n",
    "\n",
    "print('Dimension 1:')\n",
    "print(np.array(vectorizador.get_feature_names())[indices]) # Evaluamos los términos en estas posiciones\n",
    "\n",
    "print('\\n')\n",
    "\n",
    "indices = np.argsort(comp2);\n",
    "indices = indices[::-1]\n",
    "print('Dimension 2:')\n",
    "print(np.array(vectorizador.get_feature_names())[indices])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
