{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import matutils, models\n",
    "import scipy.sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import logging\n",
    "# logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/izq_econ_news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_inflation = df.loc[df.flyer.str.contains('INFLA|INDEC|SUBA|PRECIO', na=False),'body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_exchange = df.loc[df.flyer.str.contains('BRECHA|CAMBI|RESERV', na=False), 'body']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = df_inflation.append(df_exchange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8      El Indec informó que en octubre de 2020 las ex...\n",
       "10     El Estimador Mensual de la Actividad Económica...\n",
       "13     Se trata del mismo aumento que aplicó Massalin...\n",
       "15     La petrolera Raizen, dueña de la marca Shell, ...\n",
       "18     Los precios de los combustibles comercializado...\n",
       "23     ¿Cuántos días te dura el salario del mes? Segu...\n",
       "28     La Junta Interna de ATE Indec calculó la canas...\n",
       "29     El Indec informó este jueves que el Índice de ...\n",
       "35     El Indec informó este martes que la Canasta Bá...\n",
       "54     Este jueves la Dirección de Estadísticas e Inv...\n",
       "57     La suba de precios no se detiene. Según anunci...\n",
       "88     La construcción en septiembre tuvo una baja de...\n",
       "108    Los salarios pierden ante la inflación. El Ind...\n",
       "129    ¿Cuánto debería ser el salario como mínimo? la...\n",
       "137    El Indec informó que el Estimador mensual de a...\n",
       "141    Este miércoles el Indec publicó el índice de p...\n",
       "7      La Comisión Nacional de Valores (CNV) a través...\n",
       "33     El día después de la votación del Presupuesto ...\n",
       "51     El dólar blue vuelve a aumentar este viernes. ...\n",
       "59     El dólar blue tuvo un incremento de cinco peso...\n",
       "62     En medio de las reuniones con la delegación de...\n",
       "71     El dólar blue volvió a bajar este martes y se ...\n",
       "85     El Gobierno de Alberto Fernández pagó esta sem...\n",
       "94     La falta de dólares es un “problema estructura...\n",
       "110    El dólar blue descendió este jueves a $ 175, m...\n",
       "121    Este martes el Gobierno hará una emisión de de...\n",
       "125    La semana empezó con una fuerte volatilidad en...\n",
       "132    El dólar blue se vende a $ 195 y alcanza un nu...\n",
       "142    La cotización de la divisa norteamericana sigu...\n",
       "Name: body, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_sp = stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words = stopwords_sp, lowercase = True, strip_accents='unicode')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaning = [re.sub(r'(\\d|\\$|\\%|\\+)', '', doc) for doc in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guido/anaconda3/envs/dh/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    }
   ],
   "source": [
    "data = vectorizer.fit_transform(cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = pd.DataFrame(data.todense(), columns=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show resulting vocabulary; the numbers are not counts, they are the position in the sparse vector.\n",
    "# vectorizer.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_counts = scipy.sparse.csr_matrix(vectors)\n",
    "corpus = matutils.Sparse2Corpus(sparse_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "id2word = dict((v, k) for k, v in vectorizer.vocabulary_.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.118*\"acceder\" + 0.066*\"aceleraran\" + 0.059*\"aceleraria\" + 0.058*\"activos\" + 0.045*\"aceites\" + 0.044*\"acceso\" + 0.042*\"aceitera\" + 0.040*\"accesorios\" + 0.037*\"acelera\" + 0.036*\"acero\"'),\n",
       " (1,\n",
       "  '0.085*\"actual\" + 0.070*\"actualizacion\" + 0.058*\"achique\" + 0.053*\"acuerdo\" + 0.050*\"aca\" + 0.049*\"actualidad\" + 0.049*\"actividad\" + 0.043*\"activos\" + 0.043*\"abajo\" + 0.043*\"absorber\"')]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lda = models.LdaModel(corpus=corpus, id2word=id2word, num_topics=2, passes=10)\n",
    "lda.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
