{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "Load \"izquierda diario\" collected data from csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/izq_econ_news.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1032, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>flyer</th>\n",
       "      <th>lead</th>\n",
       "      <th>headline</th>\n",
       "      <th>body</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>\\nMartes 22 de diciembre</td>\n",
       "      <td>LUCRO CAPITALISTA</td>\n",
       "      <td>Varios barrios fueron afectados por la falta d...</td>\n",
       "      <td>Masivo corte de luz: Edesur y los servicios pú...</td>\n",
       "      <td>A solo un día del comienzo del verano en la Ar...</td>\n",
       "      <td>https://www.laizquierdadiario.com/Economia/Mas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>\\nMartes 22 de diciembre</td>\n",
       "      <td>INFORME JUNTA INTERNA ATE INDEC</td>\n",
       "      <td>Es el monto de una canasta de consumos mínimos...</td>\n",
       "      <td>Ningún trabajador debería ganar menos de  $ 78...</td>\n",
       "      <td>La Junta Interna de ATE Indec estimó la canast...</td>\n",
       "      <td>https://www.laizquierdadiario.com/Economia/Nin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>\\nMartes 22 de diciembre</td>\n",
       "      <td>INFORME INDEC</td>\n",
       "      <td>Los datos corresponden al informe sobre la \"Di...</td>\n",
       "      <td>La mitad de los asalariados percibe hasta $ 30...</td>\n",
       "      <td>El 50 % de los asalariados ganaba hasta $ 30.0...</td>\n",
       "      <td>https://www.laizquierdadiario.com/Economia/La-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>\\nLunes 21 de diciembre</td>\n",
       "      <td>INFORME INDEC</td>\n",
       "      <td>Al mismo tiempo los precios mayoristas del con...</td>\n",
       "      <td>Se disparó el costo de la construcción: en nov...</td>\n",
       "      <td>La inflación no se detiene y el fin de año par...</td>\n",
       "      <td>https://www.laizquierdadiario.com/Economia/Se-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>\\nLunes 21 de diciembre</td>\n",
       "      <td>CRISIS ECONOMICA</td>\n",
       "      <td>IRSA Propiedades Comerciales fue la más afecta...</td>\n",
       "      <td>Acciones argentinas en Wall Street cayeron has...</td>\n",
       "      <td>Las acciones de empresas argentinas que cotiza...</td>\n",
       "      <td>https://www.laizquierdadiario.com/Economia/Acc...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                      date                            flyer  \\\n",
       "0           0  \\nMartes 22 de diciembre               LUCRO CAPITALISTA    \n",
       "1           1  \\nMartes 22 de diciembre  INFORME JUNTA INTERNA ATE INDEC   \n",
       "2           2  \\nMartes 22 de diciembre                    INFORME INDEC   \n",
       "3           3   \\nLunes 21 de diciembre                    INFORME INDEC   \n",
       "4           4   \\nLunes 21 de diciembre                 CRISIS ECONOMICA   \n",
       "\n",
       "                                                lead  \\\n",
       "0  Varios barrios fueron afectados por la falta d...   \n",
       "1  Es el monto de una canasta de consumos mínimos...   \n",
       "2  Los datos corresponden al informe sobre la \"Di...   \n",
       "3  Al mismo tiempo los precios mayoristas del con...   \n",
       "4  IRSA Propiedades Comerciales fue la más afecta...   \n",
       "\n",
       "                                            headline  \\\n",
       "0  Masivo corte de luz: Edesur y los servicios pú...   \n",
       "1  Ningún trabajador debería ganar menos de  $ 78...   \n",
       "2  La mitad de los asalariados percibe hasta $ 30...   \n",
       "3  Se disparó el costo de la construcción: en nov...   \n",
       "4  Acciones argentinas en Wall Street cayeron has...   \n",
       "\n",
       "                                                body  \\\n",
       "0  A solo un día del comienzo del verano en la Ar...   \n",
       "1  La Junta Interna de ATE Indec estimó la canast...   \n",
       "2  El 50 % de los asalariados ganaba hasta $ 30.0...   \n",
       "3  La inflación no se detiene y el fin de año par...   \n",
       "4  Las acciones de empresas argentinas que cotiza...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.laizquierdadiario.com/Economia/Mas...  \n",
       "1  https://www.laizquierdadiario.com/Economia/Nin...  \n",
       "2  https://www.laizquierdadiario.com/Economia/La-...  \n",
       "3  https://www.laizquierdadiario.com/Economia/Se-...  \n",
       "4  https://www.laizquierdadiario.com/Economia/Acc...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['LUCRO CAPITALISTA ', 'INFORME JUNTA INTERNA ATE INDEC',\n",
       "       'INFORME INDEC', 'INFORME INDEC', 'CRISIS ECONOMICA', 'TUCUMÁN',\n",
       "       'CRISIS ECONOMICA', 'POLITICA', 'AJUSTE FISCAL ',\n",
       "       'CONGRESO NACIONAL', 'ECONOMIA NACIONAL', '¿CUÁNDO SE COBRA? ',\n",
       "       'Negocio para bonistas, ajuste para trabajadores', 'INFORME INDEC',\n",
       "       nan, 'TARIFAZOS', 'INFORME INDEC', 'DEUDA EXTERNA', 'NEUQUÉN',\n",
       "       'CONFERENCIA DE PRENSA'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.flyer.values[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Topics\n",
    "Arbitrary selection of topics from news flyers of the portal's economic section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(135, 7)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.flyer.str.contains('DEUDA|Deuda|BONO', na=False)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 7)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.flyer.str.contains('BRECHA|CAMBI|RESERV', na=False)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 7)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.flyer.str.contains('INFLA|SUBA|PRECIO|COSTO', na=False)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 7)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.flyer.str.contains('INDEC', na=False) & df.headline.str.contains('costo|precio|infla', na=False)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 7)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.flyer.str.contains('FMI|FONDO', na=False)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14, 7)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.flyer.str.contains('SALARIO|OBRER|TRABAJA', na=False)].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Corpus (Body)\n",
    "Clipping of the selected news body"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic: Inflation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "infla_mask = df.flyer.str.contains('INFLA|SUBA|PRECIO|COSTO', na=False)\n",
    "indec_mask = df.flyer.str.contains('INDEC', na=False) & df.headline.str.contains('costo|precio|infla', na=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(48, 7)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inflation = df[infla_mask | indec_mask]\n",
    "inflation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removal of dicember news to match \"derecha diario\" timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3            \\nLunes 21 de diciembre\n",
       "23          \\nMartes 15 de diciembre\n",
       "24          \\nMartes 15 de diciembre\n",
       "40        \\nMiércoles 9 de diciembre\n",
       "48            \\nLunes 7 de diciembre\n",
       "59           \\nJueves 3 de diciembre\n",
       "66         \\nMartes 1ro de diciembre\n",
       "84           \\nLunes 23 de noviembre\n",
       "86           \\nLunes 23 de noviembre\n",
       "89           \\nLunes 23 de noviembre\n",
       "94         \\nViernes 20 de noviembre\n",
       "100         \\nJueves 19 de noviembre\n",
       "106         \\nMartes 17 de noviembre\n",
       "125        \\nViernes 13 de noviembre\n",
       "128         \\nJueves 12 de noviembre\n",
       "211        \\nMiércoles 21 de octubre\n",
       "215           \\nMartes 20 de octubre\n",
       "240           \\nMartes 13 de octubre\n",
       "275     \\nMiércoles 30 de septiembre\n",
       "292       \\nViernes 25 de septiembre\n",
       "299     \\nMiércoles 23 de septiembre\n",
       "313        \\nSábado 19 de septiembre\n",
       "318        \\nJueves 17 de septiembre\n",
       "329         \\nLunes 14 de septiembre\n",
       "376           \\nViernes 21 de agosto\n",
       "384            \\nMartes 18 de agosto\n",
       "453             \\nJueves 23 de julio\n",
       "456          \\nMiércoles 22 de julio\n",
       "478          \\nMiércoles 15 de julio\n",
       "561            \\nViernes 12 de junio\n",
       "639               \\nLunes 18 de mayo\n",
       "649              \\nJueves 14 de mayo\n",
       "706             \\nJueves 23 de abril\n",
       "717             \\nMartes 21 de abril\n",
       "720              \\nLunes 20 de abril\n",
       "732          \\nMiércoles 15 de abril\n",
       "742             \\nSábado 11 de abril\n",
       "804             \\nJueves 19 de marzo\n",
       "819             \\nJueves 12 de marzo\n",
       "888        \\nMiércoles 19 de febrero\n",
       "901          \\nViernes 14 de febrero\n",
       "907        \\nMiércoles 12 de febrero\n",
       "945             \\nJueves 30 de enero\n",
       "987              \\nLunes 20 de enero\n",
       "993             \\nJueves 16 de enero\n",
       "995          \\nMiércoles 15 de enero\n",
       "1011             \\nMartes 7 de enero\n",
       "1029        \\nMiércoles 1ro de enero\n",
       "Name: date, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inflation.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35, 7)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inflation = inflation.drop(inflation[inflation.date.str.contains('diciembre|enero')].index, axis=0)\n",
    "inflation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic: Currency Exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 7)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exchange = df.loc[df.flyer.str.contains('BRECHA|CAMBI|RESERV', na=False)]\n",
    "exchange.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "78         \\nJueves 26 de noviembre\n",
       "104     \\nMiércoles 18 de noviembre\n",
       "122       \\nViernes 13 de noviembre\n",
       "130        \\nJueves 12 de noviembre\n",
       "133     \\nMiércoles 11 de noviembre\n",
       "141        \\nMartes 10 de noviembre\n",
       "155        \\nViernes 6 de noviembre\n",
       "164          \\nLunes 2 de noviembre\n",
       "180          \\nJueves 29 de octubre\n",
       "191          \\nMartes 27 de octubre\n",
       "195           \\nLunes 26 de octubre\n",
       "202         \\nViernes 23 de octubre\n",
       "212       \\nMiércoles 21 de octubre\n",
       "216          \\nMartes 20 de octubre\n",
       "219          \\nMartes 20 de octubre\n",
       "221           \\nLunes 19 de octubre\n",
       "249          \\nViernes 9 de octubre\n",
       "252           \\nJueves 8 de octubre\n",
       "258           \\nMartes 6 de octubre\n",
       "268          \\nViernes 2 de octubre\n",
       "314      \\nViernes 18 de septiembre\n",
       "317       \\nJueves 17 de septiembre\n",
       "410            \\nJueves 6 de agosto\n",
       "447           \\nViernes 24 de julio\n",
       "650             \\nJueves 14 de mayo\n",
       "735            \\nMartes 14 de abril\n",
       "1026            \\nJueves 2 de enero\n",
       "Name: date, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exchange.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 7)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exchange = exchange.drop(exchange[exchange.date.str.contains('enero')].index, axis=0)\n",
    "exchange.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare selection and pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "inflation.insert(loc=0, column='topics', value='inflation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "exchange.insert(loc=0, column='topics', value='exchange')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean = inflation.append(exchange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_clean.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(data_clean, open( \"data/df_clean_izq.pkl\", \"wb\" ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "61"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = data_clean.body.values\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization\n",
    "#### Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import unidecode\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"Stop words\", special characters, accents and numbers are removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_sp = stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(texto):\n",
    "\n",
    "    alphanumeric = re.sub(r'([^\\s\\w]|_)+', '', texto).lower()\n",
    "    no_accents = unidecode.unidecode(alphanumeric)\n",
    "    \n",
    "    tockens = word_tokenize(no_accents)\n",
    "    \n",
    "    tockens_clean = [tocken for tocken in tockens if tocken not in stopwords_sp and tocken.isalpha()]\n",
    "    \n",
    "    terminos = tockens_clean\n",
    "\n",
    "    return terminos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = [tokenizer(documento) for documento in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulario = sorted(list(set([word for group in tokenized for word in group])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3244"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulario)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removal of special characters function to load in vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removal(text):\n",
    "    text = re.sub(r'(\\d|\\$|\\%|\\+)', '', text.lower())\n",
    "    return re.sub(r'\\d+', '', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words = stopwords_sp, lowercase = True, strip_accents='unicode', preprocessor=removal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_tokens = vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3034, 3034)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.vocabulary_), len(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Manual tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token_matrix_maker(data, vocabulario):\n",
    "    matriz = np.zeros(shape = (len(data), len(vocabulario)), dtype='int')\n",
    "    for i, documento in enumerate(data):\n",
    "        for termino in documento:\n",
    "            matriz[i, vocabulario.index(termino)] += 1\n",
    "    return matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix = token_matrix_maker(tokenized, vocabulario)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataframe\n",
    "token_df = pd.DataFrame(matrix, columns=vocabulario, index = ['doc' + str(i + 1) for i in range(len(tokenized))] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add classification column\n",
    "topics = ['inflation' for i in range(len(inflation))] + ['exchange' for i in range(len(exchange))]\n",
    "token_df.insert(loc=0, column='topics', value=topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_df.to_pickle('tokens/topic_tokens_izq.pkl')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CV tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(cv_tokens, open( \"tokens/cv_izq.pkl\", \"wb\" ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
