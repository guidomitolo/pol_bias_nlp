{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Naive Bayes\n",
    "Inflation VS currency exchange in \"Izquierda Diario\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open('data/df_clean_izq.pkl','rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topics</th>\n",
       "      <th>date</th>\n",
       "      <th>flyer</th>\n",
       "      <th>lead</th>\n",
       "      <th>headline</th>\n",
       "      <th>body</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>inflation</td>\n",
       "      <td>\\nJueves 14 de mayo</td>\n",
       "      <td>PRECIOS</td>\n",
       "      <td>El Indec informó que el aumento de precios del...</td>\n",
       "      <td>Inflación de abril: la suba de alimentos y beb...</td>\n",
       "      <td>El Indec publicó que la inflación de abril fue...</td>\n",
       "      <td>https://www.laizquierdadiario.com/Economia/Inf...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>inflation</td>\n",
       "      <td>\\nMiércoles 21 de octubre</td>\n",
       "      <td>INDEC</td>\n",
       "      <td>Mientras los materiales para la construcción c...</td>\n",
       "      <td>Los precios mayoristas aumentaron 3,7 % en sep...</td>\n",
       "      <td>Este miércoles el Indec publicó el índice de p...</td>\n",
       "      <td>https://www.laizquierdadiario.com/Economia/Los...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>exchange</td>\n",
       "      <td>\\nLunes 19 de octubre</td>\n",
       "      <td>TENSIÓN CAMBIARIA</td>\n",
       "      <td>A la espera de las medidas cambiarias que anun...</td>\n",
       "      <td>Dólar blue sin techo: llegó a los $ 181</td>\n",
       "      <td>La tensión en el mercado de cambios no cede, r...</td>\n",
       "      <td>https://www.laizquierdadiario.com/Economia/Dol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>exchange</td>\n",
       "      <td>\\nMartes 27 de octubre</td>\n",
       "      <td>TENSION CAMBIARIA</td>\n",
       "      <td>También se emitirán bonos ligados a la inflaci...</td>\n",
       "      <td>Guzmán lanza un nuevo bono atado al dólar para...</td>\n",
       "      <td>Este martes el Gobierno hará una emisión de de...</td>\n",
       "      <td>https://www.laizquierdadiario.com/Economia/Guz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>exchange</td>\n",
       "      <td>\\nMartes 20 de octubre</td>\n",
       "      <td>TIPO DE CAMBIO</td>\n",
       "      <td>La reducción del “parking” a tres días no fue ...</td>\n",
       "      <td>A pesar de las medidas oficiales, el dólar par...</td>\n",
       "      <td>Luego de las medidas anunciadas por el Ministe...</td>\n",
       "      <td>https://www.laizquierdadiario.com/Economia/A-p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       topics                       date              flyer  \\\n",
       "31  inflation        \\nJueves 14 de mayo           PRECIOS    \n",
       "15  inflation  \\nMiércoles 21 de octubre              INDEC   \n",
       "52   exchange      \\nLunes 19 de octubre  TENSIÓN CAMBIARIA   \n",
       "46   exchange     \\nMartes 27 de octubre  TENSION CAMBIARIA   \n",
       "50   exchange     \\nMartes 20 de octubre     TIPO DE CAMBIO   \n",
       "\n",
       "                                                 lead  \\\n",
       "31  El Indec informó que el aumento de precios del...   \n",
       "15  Mientras los materiales para la construcción c...   \n",
       "52  A la espera de las medidas cambiarias que anun...   \n",
       "46  También se emitirán bonos ligados a la inflaci...   \n",
       "50  La reducción del “parking” a tres días no fue ...   \n",
       "\n",
       "                                             headline  \\\n",
       "31  Inflación de abril: la suba de alimentos y beb...   \n",
       "15  Los precios mayoristas aumentaron 3,7 % en sep...   \n",
       "52            Dólar blue sin techo: llegó a los $ 181   \n",
       "46  Guzmán lanza un nuevo bono atado al dólar para...   \n",
       "50  A pesar de las medidas oficiales, el dólar par...   \n",
       "\n",
       "                                                 body  \\\n",
       "31  El Indec publicó que la inflación de abril fue...   \n",
       "15  Este miércoles el Indec publicó el índice de p...   \n",
       "52  La tensión en el mercado de cambios no cede, r...   \n",
       "46  Este martes el Gobierno hará una emisión de de...   \n",
       "50  Luego de las medidas anunciadas por el Ministe...   \n",
       "\n",
       "                                                  url  \n",
       "31  https://www.laizquierdadiario.com/Economia/Inf...  \n",
       "15  https://www.laizquierdadiario.com/Economia/Los...  \n",
       "52  https://www.laizquierdadiario.com/Economia/Dol...  \n",
       "46  https://www.laizquierdadiario.com/Economia/Guz...  \n",
       "50  https://www.laizquierdadiario.com/Economia/A-p...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37, 7)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_inflation = data.loc[data.topics == 'inflation']\n",
    "df_inflation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(26, 7)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exchange = data.loc[data.topics == 'exchange']\n",
    "df_exchange.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = list(df_inflation.body.values) + list(df_exchange.body.values)\n",
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = list(df_inflation.topics.values) + list(df_exchange.topics.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>La inflación no se detiene y el fin de año par...</td>\n",
       "      <td>inflation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>La inflación de noviembre fue del 3,2 % en com...</td>\n",
       "      <td>inflation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Este martes el Indec informó que la Canasta Bá...</td>\n",
       "      <td>inflation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>El Gobierno nacional acordó con frigoríficos l...</td>\n",
       "      <td>inflation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ante la crisis económica y social que afecta a...</td>\n",
       "      <td>inflation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Tras las nuevas medidas dispuestas por el Banc...</td>\n",
       "      <td>exchange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Tras la euforia en los “mercados” por el acuer...</td>\n",
       "      <td>exchange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>El dólar blue aumentó casi $ 10 en una semana....</td>\n",
       "      <td>exchange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>El dólar blue alcanzó los $ 138, el “contado c...</td>\n",
       "      <td>exchange</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>El dólar paralelo tuvo otra jornada de suba. E...</td>\n",
       "      <td>exchange</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>63 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    0          1\n",
       "0   La inflación no se detiene y el fin de año par...  inflation\n",
       "1   La inflación de noviembre fue del 3,2 % en com...  inflation\n",
       "2   Este martes el Indec informó que la Canasta Bá...  inflation\n",
       "3   El Gobierno nacional acordó con frigoríficos l...  inflation\n",
       "4   Ante la crisis económica y social que afecta a...  inflation\n",
       "..                                                ...        ...\n",
       "58  Tras las nuevas medidas dispuestas por el Banc...   exchange\n",
       "59  Tras la euforia en los “mercados” por el acuer...   exchange\n",
       "60  El dólar blue aumentó casi $ 10 en una semana....   exchange\n",
       "61  El dólar blue alcanzó los $ 138, el “contado c...   exchange\n",
       "62  El dólar paralelo tuvo otra jornada de suba. E...   exchange\n",
       "\n",
       "[63 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame([corpus, target]).transpose()\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,test,y_train,y_test = train_test_split(data.iloc[:,0], data.iloc[:,1], train_size=0.75); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((47,), (16,))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization + Vectorization\n",
    "#### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords_sp = stopwords.words('spanish')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/guido/anaconda3/envs/dh/lib/python3.7/site-packages/sklearn/feature_extraction/text.py:386: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['eramos', 'estabamos', 'estais', 'estan', 'estara', 'estaran', 'estaras', 'estare', 'estareis', 'estaria', 'estariais', 'estariamos', 'estarian', 'estarias', 'esteis', 'esten', 'estes', 'estuvieramos', 'estuviesemos', 'fueramos', 'fuesemos', 'habeis', 'habia', 'habiais', 'habiamos', 'habian', 'habias', 'habra', 'habran', 'habras', 'habre', 'habreis', 'habria', 'habriais', 'habriamos', 'habrian', 'habrias', 'hayais', 'hubieramos', 'hubiesemos', 'mas', 'mia', 'mias', 'mio', 'mios', 'seais', 'sera', 'seran', 'seras', 'sere', 'sereis', 'seria', 'seriais', 'seriamos', 'serian', 'serias', 'si', 'tambien', 'tendra', 'tendran', 'tendras', 'tendre', 'tendreis', 'tendria', 'tendriais', 'tendriamos', 'tendrian', 'tendrias', 'teneis', 'tengais', 'tenia', 'teniais', 'teniamos', 'tenian', 'tenias', 'tuvieramos', 'tuviesemos'] not in stop_words.\n",
      "  'stop_words.' % sorted(inconsistent))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CountVectorizer(stop_words=['de', 'la', 'que', 'el', 'en', 'y', 'a', 'los',\n",
       "                            'del', 'se', 'las', 'por', 'un', 'para', 'con',\n",
       "                            'no', 'una', 'su', 'al', 'lo', 'como', 'más',\n",
       "                            'pero', 'sus', 'le', 'ya', 'o', 'este', 'sí',\n",
       "                            'porque', ...],\n",
       "                strip_accents='unicode')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(stop_words = stopwords_sp, lowercase = True, strip_accents='unicode')\n",
    "vectorizer.fit(list(re.sub(r'(\\d|\\$|\\%|\\+)', '', doc) for doc in corpus))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = vectorizer.transform(train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<47x3006 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 6045 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_matriz = X_train.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = vectorizer.transform(test);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_matriz = X_train.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tf IDf Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_matriz_tfidf = TfidfTransformer().fit_transform(X_train_matriz);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_matriz_tfidf = TfidfTransformer().fit_transform(X_test_matriz);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes + CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_nb = MultinomialNB()\n",
    "\n",
    "multi_nb.fit(X_train, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = multi_nb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6,  0],\n",
       "       [ 0, 10]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred, y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes + TfIDf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_nb_2 = MultinomialNB()\n",
    "\n",
    "multi_nb_2.fit(X_train_matriz_tfidf, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = multi_nb_2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6,  0],\n",
       "       [ 0, 10]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred, y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenization + Vectorization (Manual)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CountVectorizer with pre-built tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_tokens = pickle.load(open('tokens/topic_tokens_izq_new.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountVectorizer(stop_words=['de', 'la', 'que', 'el', 'en', 'y', 'a', 'los',\n",
       "                            'del', 'se', 'las', 'por', 'un', 'para', 'con',\n",
       "                            'no', 'una', 'su', 'al', 'lo', 'como', 'más',\n",
       "                            'pero', 'sus', 'le', 'ya', 'o', 'este', 'sí',\n",
       "                            'porque', ...],\n",
       "                strip_accents='unicode')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(cv_tokens.drop('topics', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2 = vectorizer.transform(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_matriz_2 = X_train_2.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_2 = vectorizer.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_matriz_2 = X_test_2.todense()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TF-IDF Vectorizer with pre-built tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_matriz_tfidf_2 = TfidfTransformer().fit_transform(X_train_matriz_2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_matriz_tfidf_2 = TfidfTransformer().fit_transform(X_test_matriz_2);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes + CountVectorizer (updated tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_nb = MultinomialNB()\n",
    "\n",
    "multi_nb.fit(X_train_2, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2 = multi_nb.predict(X_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred_2, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6,  0],\n",
       "       [ 0, 10]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred_2, y_test.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multinomial Naive Bayes + Tf IDf Vectorizer (updated tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_nb_2 = MultinomialNB()\n",
    "\n",
    "multi_nb_2.fit(X_train_matriz_tfidf_2, y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_2 = multi_nb_2.predict(X_test_matriz_tfidf_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_pred_2, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6,  0],\n",
       "       [ 0, 10]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_pred_2, y_test.values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
